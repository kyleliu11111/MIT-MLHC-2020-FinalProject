{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic Baselines - LOS","provenance":[{"file_id":"1xCVo8S3Pz_x-4yleF_MkRWNGzw2SslTf","timestamp":1588019404982},{"file_id":"1WDTWvfZvIrcclqAs5KMqEroQ5rtaB3yJ","timestamp":1587625813876},{"file_id":"1Jxj3hQ5pSST0KmnFG2TKUslG-00eFMWc","timestamp":1583092405360},{"file_id":"19tSvuHLZ3fawJk4_72YhU3xtLJ3FOAWd","timestamp":1582605945703},{"file_id":"1AOw9OTa6m6jEC9RBsWyWPOBdVjBcSjQQ","timestamp":1582513757775}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"sBEzAm_FGp8v","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils import data\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import pandas as pd\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","import numpy as np\n","import pickle\n","\n","from google.colab import auth\n","\n","from sklearn.model_selection import KFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import train_test_split\n","\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"khpk-ADtGvmk","colab_type":"code","colab":{}},"source":["!wget -r -N -c -np --user wqcluo --ask-password https://physionet.org/files/picdb/1.0.0/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"363L7jzp6zz3","colab_type":"code","colab":{}},"source":["# Read Data into DF\n","\n","admissions = pd.read_csv('physionet.org/files/picdb/1.0.0/ADMISSIONS.csv.gz', compression='gzip')\n","chartevents = pd.read_csv('physionet.org/files/picdb/1.0.0/CHARTEVENTS.csv.gz', compression='gzip')\n","diagnoses_icd = pd.read_csv('physionet.org/files/picdb/1.0.0/DIAGNOSES_ICD.csv.gz', compression='gzip')\n","d_icd_diagnoses = pd.read_csv('physionet.org/files/picdb/1.0.0/D_ICD_DIAGNOSES.csv.gz', compression='gzip')\n","d_items = pd.read_csv('physionet.org/files/picdb/1.0.0/D_ITEMS.csv.gz', compression='gzip')\n","d_labitems = pd.read_csv('physionet.org/files/picdb/1.0.0/D_LABITEMS.csv.gz', compression='gzip')\n","emr_symptoms = pd.read_csv('physionet.org/files/picdb/1.0.0/EMR_SYMPTOMS.csv.gz', compression='gzip')\n","icu_stays = pd.read_csv('physionet.org/files/picdb/1.0.0/ICUSTAYS.csv.gz', compression='gzip')\n","input_events = pd.read_csv('physionet.org/files/picdb/1.0.0/INPUTEVENTS.csv.gz', compression='gzip')\n","lab_events = pd.read_csv('physionet.org/files/picdb/1.0.0/LABEVENTS.csv.gz', compression='gzip')\n","patients = pd.read_csv('physionet.org/files/picdb/1.0.0/PATIENTS.csv.gz', compression='gzip')\n","prescriptions = pd.read_csv('physionet.org/files/picdb/1.0.0/PRESCRIPTIONS.csv.gz', compression='gzip')\n","surgery_vital_signs = pd.read_csv('physionet.org/files/picdb/1.0.0/SURGERY_VITAL_SIGNS.csv.gz', compression='gzip')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdDz95lpKJ6R","colab_type":"code","colab":{}},"source":["# Easier to use: \n","\n","item_dict = dict() \n","for _, row in d_items.iterrows(): \n","  item_dict[row.ITEMID] = row.LABEL\n","\n","lab_item_dict = dict()\n","for _, row in d_labitems.iterrows(): \n","  lab_item_dict[row.ITEMID] = row.LABEL\n","\n","ICD_CN_TO_ICD = dict() \n","for _, row in d_icd_diagnoses.iterrows(): \n","  ICD_CN_TO_ICD[row.ICD10_CODE_CN] = row.ICD10_CODE \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6oefTPmDrgy","colab_type":"text"},"source":["Here we include only the first admission of each patient."]},{"cell_type":"code","metadata":{"id":"vQI20hqJH2iK","colab_type":"code","colab":{}},"source":["# Clean: Include only the first admission\n","\n","admissions = admissions.sort_values(by = ['ADMITTIME'])\n","chartevents = chartevents.sort_values(by = ['CHARTTIME'])\n","lab_events = lab_events.sort_values(by = ['CHARTTIME'])\n","\n","admits_to_keep = []\n","seen_patients = set()\n","\n","for _, row in admissions.iterrows(): \n","  if row.SUBJECT_ID not in seen_patients: \n","    admits_to_keep.append(row.HADM_ID)\n","    seen_patients.add(row.SUBJECT_ID)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcz6Z57DMUSI","colab_type":"code","colab":{}},"source":["def remove_admits(df): \n","  return df[df['HADM_ID'].isin(admits_to_keep)]\n","\n","admissions = remove_admits(admissions)\n","chartevents = remove_admits(chartevents)\n","diagnoses_icd = remove_admits(diagnoses_icd)\n","emr_symptoms = remove_admits(emr_symptoms)\n","icu_stays = remove_admits(icu_stays)\n","input_events = remove_admits(input_events)\n","lab_events = remove_admits(lab_events)\n","prescriptions = remove_admits(prescriptions)\n","surgery_vital_signs = remove_admits(surgery_vital_signs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TWZym1SY-FGP","colab_type":"code","colab":{}},"source":["icu_stays['LOS'] = icu_stays['LOS'] * 24.0 # convert all icu stay LOS into hours"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rak5HJV5DvfE","colab_type":"text"},"source":["Helper functions to parse admit times."]},{"cell_type":"code","metadata":{"id":"kooUgvMHCTAV","colab_type":"code","colab":{}},"source":["from datetime import date, timedelta, time, datetime\n","\n","def to_datetime(x): \n","  li = x.split()\n","  my_date = li[0].split(\"-\")\n","  my_time = li[1].split(\":\")\n","\n","  ret = datetime(int(my_date[0]), int(my_date[1]), int(my_date[2]), int(my_time[0]), int(my_time[1]), int(my_time[2]))\n","  \n","  return ret\n","\n","age_at_admission = dict()  \n","birth_date = dict()\n","admit_date = dict() \n","for _, row in patients.iterrows(): \n","  birth_date[row.SUBJECT_ID] = to_datetime(row.DOB)\n","\n","for _, row in admissions.iterrows(): \n","  admit_date[row.SUBJECT_ID] = to_datetime(row.ADMITTIME)\n","  age_at_admission[row.SUBJECT_ID] = to_datetime(row.ADMITTIME) - birth_date[row.SUBJECT_ID]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a-Fl9r0TTcp","colab_type":"code","colab":{}},"source":["# Time since admission (hours)\n","def normalize_time(patient_id, x): \n","  delta = to_datetime(x) - admit_date[patient_id]\n","  return delta.total_seconds() / 3600.0 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rL1DdpvVh5q","colab_type":"code","colab":{}},"source":["patient_set = set([p for p in patients.SUBJECT_ID])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ss7GMc9FCcOE","colab_type":"code","colab":{}},"source":["chartevents['HOURS_IN'] = chartevents.apply(lambda row: normalize_time(row.SUBJECT_ID, row.CHARTTIME), axis=1)\n","lab_events['HOURS_IN'] = lab_events.apply(lambda row: normalize_time(row.SUBJECT_ID, row.CHARTTIME), axis=1)\n","surgery_vital_signs['HOURS_IN'] = surgery_vital_signs.apply(lambda row: normalize_time(row.SUBJECT_ID, row.MONITORTIME), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4pkadvla_k81","colab_type":"code","colab":{}},"source":["def get_feature_name(idx): \n","  if idx < (len(lab_feats)): \n","    return lab_item_dict[lab_feats[idx]]\n","  elif idx < (len(lab_feats) + len(chart_feats)): \n","    return item_dict[str(chart_feats[idx - len(lab_feats)])]\n","  elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats)): \n","    return item_dict[surgery_feats[idx - len(lab_feats) - len(chart_feats)]]\n","  elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats) + 2):\n","    return 'gender'\n","  else: \n","    return 'age'\n","\n","def get_feature_name_flattened(idx): \n","  hours_in = idx // (len(lab_feats) + len(chart_feats) + len(surgery_feats))\n","\n","  idx -= hours_in * (len(lab_feats) + len(chart_feats) + len(surgery_feats))\n","\n","  if hours_in == WINDOW_SIZE: \n","    if idx < 2: \n","      return 'gender'\n","    else: \n","      return 'age'\n","  else: \n","    if idx < (len(lab_feats)): \n","      return lab_item_dict[lab_feats[idx]]\n","    elif idx < (len(lab_feats) + len(chart_feats)): \n","      return item_dict[str(chart_feats[idx - len(lab_feats)])]\n","    elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats)): \n","      return item_dict[surgery_feats[idx - len(lab_feats) - len(chart_feats)]]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XlhXYs49KhC","colab_type":"code","colab":{}},"source":["import math \n","## Feature Set\n","\n","## Chart Features\n","chart_feats = [1001, 1002, 1003, 1004, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016]\n","\n","\n","# Surgery Vital Signs\n","surgery_feats = surgery_vital_signs['ITEMID'].value_counts().index.tolist() \n","\n","lab_feats = [5225, \n","             5097, \n","             5141, \n","             5129, \n","             5257, \n","             5114,\n","             5113,\n","             5115,\n","             5132,\n","             5136,\n","             5226,\n","             5230,\n","             5218,\n","             5224,\n","             5212,\n","             5033,\n","             5041,\n","             5223,\n","             5215,\n","             5174,\n","             5111,\n","             6317,\n","             5094,\n","             5492,\n","             5002,\n","             5075,\n","             5237,\n","             5249,\n","             5235,\n","             5239,\n","             5227,\n","             5026,\n","             5031,\n","             5024,\n","             6085\n","             ]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OSCoo8grlA9s","colab_type":"text"},"source":["We use these to index into the tensors that follow (i.e. chart_X[patient_index_of[subject_id]] is what you want, not chart_X[subject_id]. Similar for item_id's"]},{"cell_type":"code","metadata":{"id":"YObWSqyhOK7B","colab_type":"code","colab":{}},"source":["# More Helper Dicts\n","chart_index_of = dict() \n","for i in range(len(chart_feats)): \n","  chart_index_of[chart_feats[i]] = i\n","  \n","lab_index_of = dict() \n","for i in range(len(lab_feats)): \n","  lab_index_of[lab_feats[i]] = i\n","\n","surgery_index_of = dict() \n","for i in range(len(surgery_feats)): \n","  surgery_index_of[surgery_feats[i]] = i\n","\n","patient_index_of = dict() \n","cc = 0\n","for p in patient_set: \n","  patient_index_of[p] = cc \n","  cc += 1\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0ijOJ0O8Y7Z","colab_type":"code","colab":{}},"source":["GAP_TIME          = 6  # In hours\n","WINDOW_SIZE       = 24 # Data collection window: In hours\n","# Label has to be first satisfied after GAP_TIME + WINDOW_SIZE\n","\n","# Generate per-hour aggregates (w/in the window).\n","\n","chart_X = np.zeros((len(patient_set), WINDOW_SIZE, len(chart_feats)))\n","chart_Xcnt = np.zeros((len(patient_set), WINDOW_SIZE, len(chart_feats)))\n","lab_X = np.zeros((len(patient_set), WINDOW_SIZE, len(lab_feats)))\n","lab_Xcnt = np.zeros((len(patient_set), WINDOW_SIZE, len(lab_feats)))\n","surgery_X = np.zeros((len(patient_set), WINDOW_SIZE, len(surgery_feats)))\n","surgery_Xcnt = np.zeros((len(patient_set), WINDOW_SIZE, len(surgery_feats)))\n","\n","# Remove negative chart times\n","subjects_to_remove = set() \n","\n","def is_number(s):\n","    try:\n","        float(s)\n","        return True\n","    except ValueError:\n","        return False\n","\n","for _, row in lab_events[lab_events['HOURS_IN'] < WINDOW_SIZE][lab_events['ITEMID'].isin(lab_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","  elif is_number(row.VALUE): \n","    lab_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][lab_index_of[row.ITEMID]] += row.VALUENUM\n","    lab_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][lab_index_of[row.ITEMID]] += 1 \n","\n","for _, row in surgery_vital_signs[surgery_vital_signs['HOURS_IN'] < WINDOW_SIZE][surgery_vital_signs['ITEMID'].isin(surgery_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","  elif is_number(row.VALUE): \n","    surgery_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][surgery_index_of[row.ITEMID]] += row.VALUE\n","    surgery_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][surgery_index_of[row.ITEMID]] += 1 \n","\n","for _, row in chartevents[chartevents['HOURS_IN'] < WINDOW_SIZE][chartevents['ITEMID'].isin(chart_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","    continue \n","  elif is_number(row.VALUE): \n","    chart_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][chart_index_of[row.ITEMID]] += row.VALUENUM \n","    chart_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][chart_index_of[row.ITEMID]] += 1 \n","\n","for _, row in admissions.iterrows(): \n","  if normalize_time(row.SUBJECT_ID, row.DISCHTIME) < (GAP_TIME + WINDOW_SIZE): \n","    subjects_to_remove.add(row.SUBJECT_ID)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dc_Ci_sxEYny","colab_type":"text"},"source":["Here I have simple Forward/Backward Imputation implemented. If time, we can try to implement the various other ones mentioned by https://www.nature.com/articles/s41598-018-24271-9 \n","\n","global_mean is the mean of each feature over all time points and all patients. If a patient has no occurances of a feature at any time point, it's replaced by the global mean. Otherwise, we propagate values forward/backward to replace missing values. "]},{"cell_type":"code","metadata":{"id":"OkniVeTbV3t6","colab_type":"code","colab":{}},"source":["# Missing Data Imputation\n","\n","# Forward/Backward Imputation\n","\n","# Compute Global means first. \n","\n","global_chart_mean = np.zeros(len(chart_feats))\n","global_chart_num = np.zeros(len(chart_feats))\n","global_lab_mean = np.zeros(len(lab_feats)) \n","global_lab_num = np.zeros(len(lab_feats)) \n","global_surgery_mean = np.zeros(len(surgery_feats))\n","global_surgery_num = np.zeros(len(surgery_feats))\n","\n","for i in range(len(patient_set)): \n","  for j in range(WINDOW_SIZE): \n","    for k in range(len(chart_feats)): \n","      global_chart_mean[k] += chart_X[i][j][k]\n","      global_chart_num[k] += chart_Xcnt[i][j][k] \n","    for k in range(len(lab_feats)): \n","      global_lab_mean[k] += lab_X[i][j][k]\n","      global_lab_num[k] += lab_Xcnt[i][j][k] \n","    for k in range(len(surgery_feats)): \n","      global_surgery_mean[k] += surgery_X[i][j][k] \n","      global_surgery_num[k] += surgery_Xcnt[i][j][k] \n","\n","for k in range(len( chart_feats)): \n","  global_chart_mean[k] = global_chart_mean[k] / global_chart_num[k]\n","\n","for k in range(len(lab_feats)): \n","  global_lab_mean[k] = global_lab_mean[k] / global_lab_num[k]\n","\n","for k in range(len(surgery_feats)): \n","  global_surgery_mean[k] = global_surgery_mean[k] / global_surgery_num[k]\n","\n","\n","def forward_backward_impute(feats, global_mean): \n","  # INPUTS: \n","  # Feats -- (WINDOW_SIZE, num_feats)\n","  # glboal_mean -- (num_feats)\n","  # OUTPUTS: \n","  # ret -- (WINDOW_SIZE, num_feats) (imputed)\n","  ret = feats \n","  for j in range(feats.shape[1]):\n","    for i in range(1, WINDOW_SIZE): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = ret[i-1][j]\n","    for i in range(WINDOW_SIZE-2, -1, -1): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = ret[i+1][j]\n","    for i in range(WINDOW_SIZE): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = global_mean[j]\n","  return ret \n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkRov0eLbCnr","colab_type":"code","colab":{}},"source":["# Set up X, Y \n","\n","\n","# Set up labels\n","\n","patient_set = list(patient_set)\n","\n","mort_icu = dict() \n","for _, row in patients.iterrows(): \n","  if row.SUBJECT_ID in patient_set: \n","    mort_icu[row.SUBJECT_ID] = row.EXPIRE_FLAG \n","\n","gender_one_hot = np.zeros((len(patient_set), 2))\n","age_vec = np.zeros((len(patient_set), 1))\n","for _, row in patients.iterrows(): \n","  if row.SUBJECT_ID in patient_set: \n","    age_vec[patient_index_of[row.SUBJECT_ID]][0] = (age_at_admission[row.SUBJECT_ID].total_seconds() / 3600.0)\n","    if row.GENDER == 'M': \n","      gender_one_hot[patient_index_of[row.SUBJECT_ID]][0] = 1\n","    else: \n","      gender_one_hot[patient_index_of[row.SUBJECT_ID]][1] = 1\n","\n","static_vec = np.concatenate((gender_one_hot, age_vec), axis = 1)\n","# [num_patients, 3]\n","\n","chart_vec = chart_X / (chart_Xcnt + (chart_Xcnt == 0))\n","lab_vec = lab_X / (lab_Xcnt + (lab_Xcnt == 0))\n","surgery_vec = surgery_X / (surgery_Xcnt + (surgery_Xcnt == 0))\n","\n","for i in range(len(patient_set)): \n","  chart_vec[i] = forward_backward_impute(chart_vec[i], global_chart_mean)\n","  lab_vec[i] = forward_backward_impute(lab_vec[i], global_lab_mean)\n","  surgery_vec[i] = forward_backward_impute(surgery_vec[i],  global_surgery_mean)\n","\n","selected_features = [chart_vec, lab_vec, surgery_vec]\n","time_vec = np.concatenate(selected_features, axis=2)\n","# time_vec [num_patients, window_size, num_lab_features + num_chart_features + num_vital_features]\n","\n","# concatenate this with static_vec [num_patients, 3]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"szGv-3ppjq9L","colab_type":"code","colab":{}},"source":["def get_mask(removed_subjects): \n","\n","  mask = [True for p in patient_set]\n","  for p in removed_subjects:\n","    mask[patient_index_of[p]] = False\n","\n","  return mask \n","\n","def setup_data(task, model):\n","  my_subjects_to_remove = subjects_to_remove\n","  if task == 'Sepsis Prediction': \n","\n","    # Protect against labels found in the range [0, WINDOW_SIZE + GAP]. Remove these patients.\n","\n","    for _, row in admissions.iterrows(): \n","      if row.SUBJECT_ID in SEPTIC: \n","        if SEPTIC[row.SUBJECT_ID] < (GAP_TIME + WINDOW_SIZE): \n","          my_subjects_to_remove.add(row.SUBJECT_ID)\n","\n","    # Masks\n","\n","    mask = get_mask(my_subjects_to_remove)\n","\n","    # Labels \n","\n","    labels = np.zeros(len(patient_set)) \n","    for i in range(len(patient_set)): \n","      if patient_set[i] in SEPTIC: \n","        labels[i] = 1\n","      else: \n","        labels[i] = 0\n","      \n","    # Covariates\n","    if model in ['LR', 'RF']: # Linear models\n","      covars = np.concatenate((np.reshape((time_vec), (time_vec.shape[0], time_vec.shape[1] * time_vec.shape[2])), static_vec), axis = 1)\n","      \n","      return covars[mask, ...], labels[mask, ...]\n","\n","    else: # Time series models\n","\n","      # expands labels to (num_patients, window_size) from (num_patients)\n","      labels_ts = torch.from_numpy(labels[mask, ...])\n","      labels_ts = labels_ts.unsqueeze(1).expand((time_vec[mask, ...].shape[0], time_vec[mask, ...].shape[1]))\n","\n","      time_ts = torch.from_numpy(time_vec).float()\n","      static_ts = torch.from_numpy(static_vec).float().unsqueeze(1).expand((time_ts.shape[0], time_ts.shape[1], static_vec.shape[1]))\n","      covars_ts = torch.cat((time_ts, static_ts), dim=2)\n","      covars_ts = covars_ts[mask, ...]\n","\n","      return covars_ts, labels_ts\n","    \n","  elif task == 'Mortality Prediction': \n","    # No need to protect against labels in the range [0, Window + Gap] (all labels are found at discharge time).\n","\n","    # Masks \n","\n","    mask = get_mask(my_subjects_to_remove)\n","\n","    # Labels \n","\n","    labels = np.zeros(len(patient_set)) \n","    for i in range(len(patient_set)): \n","      if mort_icu[patient_set[i]] == 1:\n","        labels[i] = 1\n","      else: \n","        labels[i] = 0\n","      \n","    # Covariates\n","    if model in ['LR', 'RF']: # Linear models\n","      covars = np.concatenate((np.reshape((time_vec), (time_vec.shape[0], time_vec.shape[1] * time_vec.shape[2])), static_vec), axis = 1)\n","      \n","      return covars[mask, ...], labels[mask, ...]\n","    else: # Time series models\n","      labels_ts = torch.from_numpy(labels[mask, ...]).float()\n","      labels_ts = labels_ts.unsqueeze(1).expand((time_vec[mask, ...].shape[0], time_vec[mask, ...].shape[1]))\n","\n","      time_ts = torch.from_numpy(time_vec).float()\n","      static_ts = torch.from_numpy(static_vec).float().unsqueeze(1).expand((time_ts.shape[0], time_ts.shape[1], static_vec.shape[1]))\n","      covars_ts = torch.cat((time_ts, static_ts), dim=2)\n","      covars_ts = covars_ts[mask, ...]\n","\n","      return covars_ts, labels_ts\n","  \n","  elif task[0] == 'LOS Prediction':\n","\n","    for _, row in admissions.iterrows(): \n","      if row.SUBJECT_ID in icu_stays['SUBJECT_ID']: \n","        icu_stay_time = icu_stays.loc[icu_stays['SUBJECT_ID']==row.SUBJECT_ID]['LOS'].iloc[0]\n","        if icu_stay_time < (GAP_TIME + WINDOW_SIZE) or icu_stay_time >= 66 * 24.0:  # 66 days (times 24 hours/day) is 99th percentile \n","          my_subjects_to_remove.add(row.SUBJECT_ID)\n","      else:\n","        my_subjects_to_remove.add(row.SUBJECT_ID)\n","        # raise Exception('found an ID in admissions not in ICU stays {}'.format(row.SUBJECT_ID))\n","    \n","    mask = get_mask(my_subjects_to_remove)\n","\n","    labels = np.zeros(len(patient_set)) \n","    for i in range(len(patient_set)): \n","      icu_stay_time = icu_stays.loc[icu_stays['SUBJECT_ID']==patient_set[i]]['LOS'].iloc[0]\n","      if task[1] == 'regression':\n","        labels[i] = icu_stay_time\n","      else:\n","        labels[i] = 1 if icu_stay_time > task[1] else 0\n","    \n","    # Covariates\n","    if model in ['LR', 'RF']: # Linear models\n","      covars = np.concatenate((np.reshape((time_vec), (time_vec.shape[0], time_vec.shape[1] * time_vec.shape[2])), static_vec), axis = 1)\n","      \n","      return covars[mask, ...], labels[mask, ...]\n","    else: # Time series models\n","      labels_ts = torch.from_numpy(labels[mask, ...]).float()\n","      labels_ts = labels_ts.unsqueeze(1).expand((time_vec[mask, ...].shape[0], time_vec[mask, ...].shape[1]))\n","\n","      time_ts = torch.from_numpy(time_vec).float()\n","      static_ts = torch.from_numpy(static_vec).float().unsqueeze(1).expand((time_ts.shape[0], time_ts.shape[1], static_vec.shape[1]))\n","      covars_ts = torch.cat((time_ts, static_ts), dim=2)\n","      covars_ts = covars_ts[mask, ...]\n","\n","      return covars_ts, labels_ts\n","\n","  else: \n","    return 0, 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y0LyoBbValp-","colab_type":"code","colab":{}},"source":["from sklearn.metrics import roc_curve\n","def plot_roc(title, labels, probs): \n","  fpr, tpr, thresholds = roc_curve(labels, probs) \n","  plt.figure()\n","  plt.plot(fpr, tpr, label=title)\n","  plt.plot([0, 1], [0, 1],'r--')\n","  plt.xlim([0.0, 1.0])\n","  plt.ylim([0.0, 1.05])\n","  plt.xlabel('1 - Specificity')\n","  plt.ylabel('Sensitivity')\n","  plt.title('ROC')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10cnz5AjMg-f","colab_type":"text"},"source":["Note we need to further preprocess this data (zero mean, unit variance, PCA, etc..)\n"]},{"cell_type":"markdown","metadata":{"id":"MHdEiweyE1aA","colab_type":"text"},"source":["K-Fold Cross Validation, computes average AUC "]},{"cell_type":"code","metadata":{"id":"v_T9LpVM18p-","colab_type":"code","colab":{}},"source":["def key_fn(tup):\n","  return abs(tup[0])\n","\n","def sort_importance(coefficients, feat_name_fn):\n","  coef_shape = coefficients.shape\n","  print(coef_shape)\n","  importance = []\n","\n","  for i in range(coef_shape[1]):\n","    importance.append((coefficients[0,i], feat_name_fn(i)))\n","    # print('index {} gives {}'.format(i, feat_name_fn(i)))\n","  \n","  return sorted(importance, key=key_fn, reverse=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dO2_0Lgqter7","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression\n","\n","# X [num_patients, WINDOW_SIZE, num_features] (for LSTM)\n","# X [num_patients, WINDOW_SIZE * num_features] (for RF) \n","# Y [num_patients, WINDOW_SIZE] (for LSTM) \n","# Y [num_patients] (for RF)\n","# Sepsis Prediction\n","\n","def los_predict_basic(num_days, cohorts=None, thresholds=None, model='RF', n_splits=4, display_importance=False, get_feature_name_fn=None):\n","  X, Y = setup_data(task=('LOS Prediction', num_days * 24.0), model=model)\n","  # print(X)\n","\n","  mask = [True for p in range(len(X))]\n","  if thresholds is None:\n","    thresholds = [-1, 1e12]\n","    cohorts=['Total']\n","\n","  for i in range(len(thresholds)): \n","    print(f'----------------------- LOS PREDICTION WITH {num_days} DAYS, COHORT {cohorts[i]} ----------------------------')\n","    if i == 0: \n","      mask = [True for p in range(len(X))]\n","    else: \n","      for p in range(len(X)): \n","        mask[p] = True\n","        age = static_vec[p][-1]\n","        if (age <= thresholds[i-1]) or (age > thresholds[i]): \n","          mask[p] = False\n","\n","    X_mask = X[mask, ...]\n","    Y_mask = Y[mask, ...]\n","\n","    kf = KFold(n_splits=n_splits, shuffle=True)\n","    kf.get_n_splits(X_mask)\n","\n","    avg_auc = 0\n","    avg_acc = 0 \n","\n","    for train_index, test_index in kf.split(X_mask):\n","      x_train, x_test = X_mask[train_index], X_mask[test_index]\n","      y_train, y_test = Y_mask[train_index], Y_mask[test_index]\n","      # print(type(x_train))\n","\n","      my_scaler = StandardScaler()\n","\n","      x_train = my_scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n","      x_test = my_scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n","\n","      if model == 'RF':\n","        model = RandomForestClassifier(n_estimators=1000, \n","                                    # bootstrap = True,\n","                                    max_depth=10,\n","                                    max_features = 'sqrt')\n","      elif model == 'LR':\n","        model = LogisticRegression(max_iter=1000, C=0.1)\n","\n","      model.fit(x_train, y_train)\n","\n","      if display_importance:\n","        print(sort_importance(model.coef_, get_feature_name_fn))\n","\n","      rf_predictions = model.predict(x_test)\n","      rf_probs = model.predict_proba(x_test)[:, 1]\n","\n","      auc = roc_auc_score(y_test, rf_probs)\n","      acc = np.sum(rf_predictions == y_test) / len(y_test)\n","\n","      print(\"AUC of \", auc)\n","      print(\"ACC of \", acc)\n","\n","      avg_auc += auc\n","      avg_acc += acc\n","\n","    avg_auc /= n_splits\n","    avg_acc /= n_splits\n","\n","    print('avg AUC:', avg_auc, 'avg ACC:', avg_acc)\n","    # return avg_auc, avg_acc\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GX19bksuD5rU","colab_type":"code","colab":{}},"source":["COHORTS = ['Total', '0 - 2 Month', '2 Month - 2 Years', '2 Years - 5 Years', '5 Years - 12 Years']\n","THRESHOLDS = [-1, 60 * 24, 2 * 365 * 24, 5 * 365 * 24, 12 *  365 * 24]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oa-HpRZvD0LF","colab_type":"code","colab":{}},"source":["los_predict_basic(num_days=3, cohorts=COHORTS, thresholds=THRESHOLDS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sw5zhqtBIDzP","colab_type":"code","colab":{}},"source":["los_predict_basic(num_days=7, cohorts=COHORTS, thresholds=THRESHOLDS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkCElV17JTzp","colab_type":"code","colab":{}},"source":["los_predict_basic(num_days=3, model='LR', display_importance=True, get_feature_name_fn=get_feature_name_flattened)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pO7WicMRJrXe","colab_type":"code","colab":{}},"source":["los_predict_basic(num_days=7, model='LR', display_importance=True, get_feature_name_fn=get_feature_name_flattened)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cD9ZpZ0CtMbi","colab_type":"code","colab":{}},"source":["from sklearn.linear_model import LogisticRegression\n","\n","# X [num_patients, WINDOW_SIZE, num_features] (for LSTM)\n","# X [num_patients, WINDOW_SIZE * num_features] (for RF) \n","# Y [num_patients, WINDOW_SIZE] (for LSTM) \n","# Y [num_patients] (for RF)\n","# Sepsis Prediction\n","\n","def mort_predict_basic(cohorts=None, thresholds=None, model='RF', n_splits=4, display_importance=False, get_feature_name_fn=None):\n","  X, Y = setup_data(task='Mortality Prediction', model=model)\n","\n","  mask = [True for p in range(len(X))]\n","  if thresholds is None:\n","    thresholds = [-1, 1e12]\n","    cohorts=['Total']\n","\n","  for i in range(len(thresholds)): \n","    print(f'----------------------- MORTALITY PREDICTION, COHORT {cohorts[i]} ----------------------------')\n","    if i == 0: \n","      mask = [True for p in range(len(X))]\n","    else: \n","      for p in range(len(X)): \n","        mask[p] = True\n","        age = static_vec[p][-1]\n","        if (age <= thresholds[i-1]) or (age > thresholds[i]): \n","          mask[p] = False\n","\n","    X_mask = X[mask, ...]\n","    Y_mask = Y[mask, ...]\n","\n","    kf = KFold(n_splits=n_splits, shuffle=True)\n","    kf.get_n_splits(X_mask)\n","\n","    avg_auc = 0\n","    avg_acc = 0 \n","\n","    for train_index, test_index in kf.split(X_mask):\n","      x_train, x_test = X_mask[train_index], X_mask[test_index]\n","      y_train, y_test = Y_mask[train_index], Y_mask[test_index]\n","\n","      my_scaler = StandardScaler()\n","\n","      x_train = my_scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n","      x_test = my_scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n","\n","      if model == 'RF':\n","        model = RandomForestClassifier(n_estimators=1000, \n","                                    # bootstrap = True,\n","                                    max_depth=10,\n","                                    max_features = 'sqrt')\n","      elif model == 'LR':\n","        model = LogisticRegression(max_iter=1000, C=0.1)\n","\n","      model.fit(x_train, y_train)\n","\n","      if display_importance:\n","        print(sort_importance(model.coef_, get_feature_name_fn))\n","\n","      rf_predictions = model.predict(x_test)\n","      rf_probs = model.predict_proba(x_test)[:, 1]\n","\n","      auc = roc_auc_score(y_test, rf_probs)\n","      acc = np.sum(rf_predictions == y_test) / len(y_test)\n","\n","      print(\"AUC of \", auc)\n","      print(\"ACC of \", acc)\n","\n","      avg_auc += auc\n","      avg_acc += acc\n","\n","    avg_auc /= n_splits\n","    avg_acc /= n_splits\n","\n","    print(avg_auc, avg_acc)\n","    # return avg_auc, avg_acc\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U8WkS5Q487cE","colab_type":"code","colab":{}},"source":["COHORTS = ['Total', '0 - 2 Month', '2 Month - 2 Years', '2 Years - 5 Years', '5 Years - 12 Years']\n","THRESHOLDS = [-1, 60 * 24, 2 * 365 * 24, 5 * 365 * 24, 12 *  365 * 24]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-8U3U0et921","colab_type":"code","colab":{}},"source":["mort_predict_basic(cohorts=COHORTS, thresholds=THRESHOLDS)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VSIm4JnBumYo","colab_type":"code","colab":{}},"source":["mort_predict_basic(model='LR', display_importance=True, get_feature_name_fn=get_feature_name_flattened)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L463pzOyKVhl","colab_type":"code","colab":{}},"source":["  X, Y = setup_data(task=('LOS Prediction', 'regression'), model='RF')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Unw8e5Jd5H7u","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import cross_val_score, GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.preprocessing import MinMaxScaler\n","\n","def rfr_model(X, y, param_grid):\n","    # Perform Grid-Search\n","    # if param_grid is None:\n","    #   param_grid={\n","    #         'max_depth': range(5,7),\n","    #         'n_estimators': (100, 1000,),\n","    #         # 'max_features' : 'sqrt',\n","    #     }\n","    gscv = GridSearchCV(\n","        estimator=RandomForestRegressor(),\n","        param_grid=param_grid,\n","        cv=4, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1, refit=True)\n","    \n","    gscv.fit(X, y)\n","    best_params = gscv.best_params_\n","    best_score = gscv.best_score_\n","    \n","    # rfr = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"], random_state=False, verbose=False)\n","    \n","    return gscv, best_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mSrpd7nvD9IT","colab_type":"code","colab":{}},"source":["# gscv_los, best_mse = rfr_model(X, Y, param_grid={\n","#                'max_depth': range(5,7),\n","#             'n_estimators': (100, 1000,),\n","#             # 'max_features' : 'sqrt',\n","# })\n","# # print(best_mse)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nk_Cy4_YeBz","colab_type":"code","colab":{}},"source":["# print(best_mse, gscv_los.best_params_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FLBFtEeJHpPv","colab_type":"code","colab":{}},"source":["gscv_los_2, best_mse_2 = rfr_model(X, Y, param_grid={\n","    # 'max_depth': range(),\n","    'n_estimators': (10, 50, 1000),\n","    'max_features' : ('sqrt',),\n","})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVSbhn6_I2e-","colab_type":"code","colab":{}},"source":["print(best_mse_2, gscv_los_2.best_params_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p8hulqviJW9N","colab_type":"code","colab":{}},"source":["gscv_los_3, best_mse_3 = rfr_model(X, Y, param_grid={\n","    'max_depth': range(6, 10),\n","    'n_estimators': (10, 50, 1000, 2000),\n","    'max_features' : ('sqrt',),\n","})"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SnK_hRKxJz0S","colab_type":"code","colab":{}},"source":["print(best_mse_3, gscv_los_3.best_params_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7E6feWzB-nOH","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LhVB4NYw9qZ7","colab_type":"code","colab":{}},"source":["def convert_float_tensor(X):\n","  return torch.tensor(X).float()\n","\n","def perturb_features(model, X, feature_range=None):\n","  if feature_range is None:\n","    feature_range = (0, X.shape[2])\n","\n","  print(feature_range)\n","  perturb_effects = []\n","  tensor_x = convert_float_tensor(X)\n","  orig_out = model(tensor_x)\n","\n","  for ind in range(feature_range[0], feature_range[1]):\n","    variable_name = get_feature_name(ind)\n","    # print(f'Dealing with variable {variable_name}')\n","    new_x = X.copy()\n","    perturbation = np.random.normal(0.0, 0.2, size=new_x.shape[:2])\n","    new_x[:, :, ind] = new_x[:, :, ind] + perturbation\n","    perturbed_out = model(convert_float_tensor(new_x))\n","    effect = ((orig_out - perturbed_out) ** 2).mean() ** 0.5\n","    print(f'Variable {ind+1} name ({variable_name}), perturbation effect: {effect:.4f}')\n","    perturb_effects.append((effect, variable_name, ind))\n","  \n","  return sorted(perturb_effects, key=key_fn, reverse=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnnolY1UxTOA","colab_type":"code","colab":{}},"source":["class LSTM_Classifier(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers=1, dropout=0., bidirectional=False):\n","    super(LSTM_Classifier, self).__init__()\n","\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers \n","    self.bidirectional = bidirectional\n","    self.dropout = dropout\n","\n","    self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True,\n","                      dropout=dropout, bidirectional=bidirectional)\n","    self.out = nn.Linear(hidden_size + hidden_size * int(bidirectional), 1)\n","\n","  def forward(self, input):\n","    # Input is (1, seq_len, input_size)\n","    rnn_out, _ = self.rnn(input)\n","    # rnn_out is (1, seq_len, directions * hidden_size)\n","    # output is (1, seq_len, 1)\n","    return self.out(rnn_out)\n","\n","def rnn_train_one_sample(model, criterion, rnn_optimizer, sent_tensor, tag_tensor, alpha = 0.5, clip=None):\n","\n","    # sent_tensor is (Num Hours, Num feats)\n","    # tag_tensor is (Num Hours)\n","\n","    model.zero_grad() \n","\n","    outputs = model(sent_tensor.unsqueeze(0)).squeeze(2).squeeze(0)\n","\n","    # loss = criterion(outputs, tag_tensor) * alpha + criterion(outputs[-1], tag_tensor[-1]) * (1.0-alpha)\n","    loss = criterion(outputs[-1], tag_tensor[-1]) \n","\n","    rnn_optimizer.zero_grad()\n","    loss.backward()\n","\n","    if clip != None: \n","      torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=clip)\n","\n","    rnn_optimizer.step()\n","\n","    return outputs, loss.item()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jhgk4icHmNFz","colab_type":"code","colab":{}},"source":["import time\n","import math\n","import sklearn\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def evaluate_result(true_tag_list, predicted_tag_list, probs):\n","  return np.mean(true_tag_list.numpy() == predicted_tag_list), roc_auc_score(true_tag_list, probs)\n","\n","# Make prediction for one sentence.\n","def rnn_predict_one_sent(model, sent_tensor):\n","  \n","    outputs = model(sent_tensor.unsqueeze(0)).squeeze(2).squeeze(0)\n","    prob = torch.sigmoid(outputs[-1])\n","\n","    predicted_tag_id = 0\n","    if prob > 0.5: \n","      predicted_tag_id = 1\n","    \n","    return predicted_tag_id, prob.item()\n","\n","\n","def evaluate_rnn(model, x_test, y_test, mask=None): \n","  if mask is None:\n","    mask = [True for i in range(len(x_test))]\n","  x_test = torch.from_numpy(x_test).float()\n","  x_test = x_test[mask, ...]\n","  y_test = y_test[mask, ...]\n","\n","  model.eval()\n","  predicted_tags = []\n","  probs = []\n","\n","  for i in range(len(x_test)): \n","    sent_tensor = x_test[i]\n","    sent_tensor = sent_tensor.to(device)\n","    predicted_tag_id, prob = rnn_predict_one_sent(model, sent_tensor)\n","    predicted_tags.append(predicted_tag_id)\n","    probs.append(prob)\n","\n","  acc, auc = evaluate_result(y_test[:, -1], predicted_tags, probs)\n","\n","  return auc, acc, predicted_tags, probs \n","\n","def train_model(model, criterion, optimizer, X_train, Y_train, X_test, Y_test, n_epochs=5, print_every=1000, plot_every=50, learning_rate=1e-3, alpha = 0.5, clip=None): \n","\n","  iter_count = 0\n","\n","  current_loss = 0\n","  current_norm = 0\n","  all_losses = []\n","  all_norms = []\n","\n","  start = time.time()\n","\n","  model.train()\n","  for epoch_i in range(n_epochs):\n","\n","    for i in range(X_train.shape[0]): \n","        sent_tensor = torch.tensor(X_train[i]).float()\n","        tag_tensor = Y_train[i]\n","\n","        sent_tensor = sent_tensor.to(device)\n","        tag_tensor = tag_tensor.to(device)\n","  \n","        output, loss = rnn_train_one_sample(model, criterion, optimizer, sent_tensor, tag_tensor, alpha=alpha, clip=clip)\n","        current_loss += loss\n","\n","        if iter_count % print_every == 0:\n","            print('%d %s %.4f' % (iter_count, timeSince(start), current_loss / print_every))\n","            current_loss = 0\n","\n","        iter_count += 1\n","\n","    auc, acc, _, _ = evaluate_rnn(model, X_test, Y_test)\n","    print(\"Epoch \", epoch_i, \" ACC of \", acc, \" AUC of \", auc)\n","  return all_losses, all_norms\n","\n","def plot_losses(losses): \n","  plt.figure()\n","  plt.title('Losses vs Iterations')\n","  plt.plot(losses)\n","  plt.show()\n","\n","def plot_norms(norms): \n","  plt.figure()\n","  plt.title('Norms vs Iterations')\n","  plt.plot(norms)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_sjaOKT1q85","colab_type":"code","colab":{}},"source":["# Evaluation\n","\n","def train_rnn(X,Y, imbalanced=False, \n","              n_epochs=10, \n","              rnn_clip = 1.0, \n","              rnn_hidden_size = 32, \n","              rnn_num_layers = 2, \n","              learning_rate = 1e-4, \n","              rnn_dropout = 0.5, \n","              rnn_alpha = 0.5, \n","              weight_decay = 1e-4,\n","              rnn_bidirectional = False,\n","              cohort_mask=None): \n","\n","  if cohort_mask is not None:\n","    X = X[cohort_mask, ...]\n","    Y = Y[cohort_mask, ...]\n","  \n","  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n","  x_test_orig = x_test\n","\n","  scaler = StandardScaler()\n","\n","  x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n","  x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n","\n","  if imbalanced: \n","    x_train = torch.from_numpy(x_train).float()\n","    x_train = torch.reshape(x_train, (x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n","    y_train = y_train[:, -1]\n","\n","    x_train, y_train = oversample(x_train, y_train)\n","\n","    x_train = torch.from_numpy(x_train).float()\n","    x_train = x_train.reshape(x_train.shape[0], WINDOW_SIZE, (int)(x_train.shape[1] / WINDOW_SIZE))\n","    y_train = torch.from_numpy(y_train).float()\n","    y_train = y_train.unsqueeze(1).expand((y_train.shape[0], WINDOW_SIZE))\n","\n","  num_feats = x_train.shape[2]\n","\n","  rnn_model = LSTM_Classifier(input_size=num_feats, hidden_size=rnn_hidden_size, num_layers=rnn_num_layers, dropout=rnn_dropout, bidirectional=rnn_bidirectional)\n","  criterion = nn.BCEWithLogitsLoss()\n","  rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","  losses, norms = train_model(rnn_model, criterion, rnn_optimizer, x_train, y_train, x_test, y_test, n_epochs=n_epochs, alpha=rnn_alpha, clip=rnn_clip)\n","\n","  return rnn_model, x_test, y_test, x_test_orig\n","\n","def run_task_lstm(task, epochs=20, rnn_hidden_size=64, weight_decay=5e-3): \n","  # if task in ['Sepsis Prediction']: \n","  #   model, x_test, y_test, x_test_orig = train_rnn(task, imbalanced=True, n_epochs=epochs)\n","  # else: \n","  #   model, x_test, y_test, x_test_orig = train_rnn(task, imbalanced=False, n_epochs=epochs, rnn_hidden_size=rnn_hidden_size, weight_decay=weight_decay, cohort_mask=)\n","\n","  all_auc = []\n","  all_acc = []\n","  all_probs = []\n","  all_preds = []\n","  all_labels = []\n","\n","  X, Y = setup_data(task = task, model = 'LSTM')\n","\n","  cohorts = ['Total', '0 - 2 Month', '2 Month - 2 Years', '2 Years - 5 Years', '5 Years - 12 Years']\n","  threshs = [-1, 60 * 24, 2 * 365 * 24, 5 * 365 * 24, 12 *  365 * 24]\n","\n","  mask = [True for p in range(len(X))]\n","  for i in range(len(threshs)): \n","    if i == 0: \n","      mask = [True for p in range(len(X))]\n","    else: \n","      for p in range(len(X)): \n","        mask[p] = True\n","        age = X[p][-1][-1]\n","        if (age <= threshs[i-1]) or (age > threshs[i]): \n","          mask[p] = False\n","    \n","    for _ in range(5):\n","      print(f'---------------------- RUNNING TASK {task} ON COHORT {cohorts[i]} ---------------------')\n","    \n","    lstm_model, x_test, y_test, x_test_orig = train_rnn(X, Y, imbalanced=False, n_epochs=epochs, rnn_hidden_size=rnn_hidden_size, weight_decay=weight_decay, cohort_mask=mask)\n","\n","    effects = perturb_features(lstm_model, x_test)\n","    print(effects)\n","    for ind, t in enumerate(effects, 1):\n","      print(ind, t[1])\n","\n","    auc, acc, rf_preds, rf_probs = evaluate_rnn(lstm_model, x_test, y_test)\n","    all_auc.append(auc)\n","    all_acc.append(acc)\n","    all_probs.append(rf_probs)\n","    all_preds.append(rf_preds)\n","    all_labels.append(y_test[:, -1])\n","\n","  return cohorts, all_auc, all_acc, all_probs, all_preds, all_labels\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SId853IVZLSx","colab_type":"text"},"source":["Set up data and evaluate."]},{"cell_type":"code","metadata":{"id":"G-2hNq88aBMt","colab_type":"code","colab":{}},"source":["los3_cohorts, los3_all_auc, los3_all_acc, los3_all_probs, los3_all_preds, los3_all_labels = run_task_lstm(('LOS Prediction', 3*24), epochs=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2UNkYSN8aSr7","colab_type":"code","colab":{}},"source":["los7_cohorts, los7_all_auc, los7_all_acc, los7_all_probs, los7_all_preds, los7_all_labels=run_task_lstm(('LOS Prediction', 7*24), epochs=5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvYuuSbuaaD7","colab_type":"code","colab":{}},"source":["mort_cohorts, mort_all_auc, mort_all_acc, mort_all_probs, mort_all_preds, mort_all_labels=run_task_lstm('Mortality Prediction', epochs=4)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L9nQknnDRm9E","colab_type":"code","colab":{}},"source":["lstm_test_los3 = True\n","\n","if lstm_test_los3:\n","  num_days=3\n","  lstm_model, x_test, y_test, cohorts, all_auc, all_acc, all_probs, all_preds, all_labels = run_task_lstm(('LOS Prediction', num_days*24), epochs=5)\n","  print(cohorts) \n","  print(all_auc)\n","  print(all_acc)\n","  print([len(all_labels[i]) for i in range(len(all_labels))])\n","  print([torch.sum(all_labels[i]).item() for i in range(len(all_labels))])\n","\n","  plt.title('LSTM ROC Curves - LOS < 3 Days')\n","  for i in range(len(cohorts)): \n","    fpr, tpr, thresholds = roc_curve(all_labels[i], all_probs[i])\n","    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (cohorts[i], all_auc[i]))\n","\n","  plt.plot([0, 1], [0, 1],'r--')\n","  plt.xlim([0.0, 1.0])\n","  plt.ylim([0.0, 1.05])\n","  plt.xlabel('1-Specificity')\n","  plt.ylabel('Sensitivity')\n","  plt.legend(loc=\"lower right\")\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EXVATQPxRG_5","colab_type":"code","colab":{}},"source":[" if lstm_test_los3:\n","  x_test=np.array(x_test, dtype=np.double)\n","  effects = perturb_features(lstm_model, x_test)\n","  print(effects)\n","  for t in effects:\n","    print(t[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xs7gUEAgXFsH","colab_type":"code","colab":{}},"source":["# effects = perturb_features(lstm_model, x_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAp-qQBAleh_","colab_type":"code","colab":{}},"source":["# print(effects)\n","# for t in effects:\n","#   print(t[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ptFEzVfwGwV","colab_type":"code","colab":{}},"source":["lstm_test_mort = True\n","\n","if lstm_test_mort:\n","  lstm_model, x_test, y_test, cohorts, all_auc, all_acc, all_probs, all_preds, all_labels = run_task_lstm('Mortality Prediction', epochs=5)\n","  print(cohorts) \n","  print(all_auc)\n","  print(all_acc)\n","  print([len(all_labels[i]) for i in range(len(all_labels))])\n","  print([torch.sum(all_labels[i]).item() for i in range(len(all_labels))])\n","\n","  plt.title('LSTM ROC Curves - Mortality')\n","  for i in range(len(cohorts)): \n","    fpr, tpr, thresholds = roc_curve(all_labels[i], all_probs[i])\n","    plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (cohorts[i], all_auc[i]))\n","\n","  plt.plot([0, 1], [0, 1],'r--')\n","  plt.xlim([0.0, 1.0])\n","  plt.ylim([0.0, 1.05])\n","  plt.xlabel('1-Specificity')\n","  plt.ylabel('Sensitivity')\n","  plt.legend(loc=\"lower right\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2R6IrOCxeCt","colab_type":"code","colab":{}},"source":[" if lstm_test_mort:\n","  x_test=np.array(x_test, dtype=np.double)\n","  effects = perturb_features(lstm_model, x_test)\n","  print(effects)\n","  for t in effects:\n","    print(t[1])"],"execution_count":0,"outputs":[]}]}