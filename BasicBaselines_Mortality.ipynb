{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Basic Baselines - Mortality","provenance":[{"file_id":"1xCVo8S3Pz_x-4yleF_MkRWNGzw2SslTf","timestamp":1588019404982},{"file_id":"1WDTWvfZvIrcclqAs5KMqEroQ5rtaB3yJ","timestamp":1587625813876},{"file_id":"1Jxj3hQ5pSST0KmnFG2TKUslG-00eFMWc","timestamp":1583092405360},{"file_id":"19tSvuHLZ3fawJk4_72YhU3xtLJ3FOAWd","timestamp":1582605945703},{"file_id":"1AOw9OTa6m6jEC9RBsWyWPOBdVjBcSjQQ","timestamp":1582513757775}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"sBEzAm_FGp8v","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils import data\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import pandas as pd\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","import numpy as np\n","import pickle\n","\n","from google.colab import auth\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"khpk-ADtGvmk","colab_type":"code","colab":{}},"source":["!wget -r -N -c -np --user kyleliu --ask-password https://physionet.org/files/picdb/1.0.0/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"363L7jzp6zz3","colab_type":"code","colab":{}},"source":["# Read Data into DF\n","\n","admissions = pd.read_csv('physionet.org/files/picdb/1.0.0/ADMISSIONS.csv.gz', compression='gzip')\n","chartevents = pd.read_csv('physionet.org/files/picdb/1.0.0/CHARTEVENTS.csv.gz', compression='gzip')\n","diagnoses_icd = pd.read_csv('physionet.org/files/picdb/1.0.0/DIAGNOSES_ICD.csv.gz', compression='gzip')\n","d_icd_diagnoses = pd.read_csv('physionet.org/files/picdb/1.0.0/D_ICD_DIAGNOSES.csv.gz', compression='gzip')\n","d_items = pd.read_csv('physionet.org/files/picdb/1.0.0/D_ITEMS.csv.gz', compression='gzip')\n","d_labitems = pd.read_csv('physionet.org/files/picdb/1.0.0/D_LABITEMS.csv.gz', compression='gzip')\n","emr_symptoms = pd.read_csv('physionet.org/files/picdb/1.0.0/EMR_SYMPTOMS.csv.gz', compression='gzip')\n","icu_stays = pd.read_csv('physionet.org/files/picdb/1.0.0/ICUSTAYS.csv.gz', compression='gzip')\n","input_events = pd.read_csv('physionet.org/files/picdb/1.0.0/INPUTEVENTS.csv.gz', compression='gzip')\n","lab_events = pd.read_csv('physionet.org/files/picdb/1.0.0/LABEVENTS.csv.gz', compression='gzip')\n","patients = pd.read_csv('physionet.org/files/picdb/1.0.0/PATIENTS.csv.gz', compression='gzip')\n","prescriptions = pd.read_csv('physionet.org/files/picdb/1.0.0/PRESCRIPTIONS.csv.gz', compression='gzip')\n","surgery_vital_signs = pd.read_csv('physionet.org/files/picdb/1.0.0/SURGERY_VITAL_SIGNS.csv.gz', compression='gzip')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdDz95lpKJ6R","colab_type":"code","colab":{}},"source":["# Easier to use: \n","\n","item_dict = dict() \n","for _, row in d_items.iterrows(): \n","  item_dict[row.ITEMID] = row.LABEL\n","\n","lab_item_dict = dict()\n","for _, row in d_labitems.iterrows(): \n","  lab_item_dict[row.ITEMID] = row.LABEL\n","\n","ICD_CN_TO_ICD = dict() \n","for _, row in d_icd_diagnoses.iterrows(): \n","  ICD_CN_TO_ICD[row.ICD10_CODE_CN] = row.ICD10_CODE \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6oefTPmDrgy","colab_type":"text"},"source":["Here we include only the first admission of each patient."]},{"cell_type":"code","metadata":{"id":"vQI20hqJH2iK","colab_type":"code","colab":{}},"source":["# Clean: Include only the first admission\n","\n","admissions = admissions.sort_values(by = ['ADMITTIME'])\n","chartevents = chartevents.sort_values(by = ['CHARTTIME'])\n","lab_events = lab_events.sort_values(by = ['CHARTTIME'])\n","\n","admits_to_keep = []\n","seen_patients = set()\n","\n","for _, row in admissions.iterrows(): \n","  if row.SUBJECT_ID not in seen_patients: \n","    admits_to_keep.append(row.HADM_ID)\n","    seen_patients.add(row.SUBJECT_ID)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcz6Z57DMUSI","colab_type":"code","colab":{}},"source":["def remove_admits(df): \n","  return df[df['HADM_ID'].isin(admits_to_keep)]\n","\n","admissions = remove_admits(admissions)\n","chartevents = remove_admits(chartevents)\n","diagnoses_icd = remove_admits(diagnoses_icd)\n","emr_symptoms = remove_admits(emr_symptoms)\n","icu_stays = remove_admits(icu_stays)\n","input_events = remove_admits(input_events)\n","lab_events = remove_admits(lab_events)\n","prescriptions = remove_admits(prescriptions)\n","surgery_vital_signs = remove_admits(surgery_vital_signs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rak5HJV5DvfE","colab_type":"text"},"source":["Helper functions to parse admit times."]},{"cell_type":"code","metadata":{"id":"kooUgvMHCTAV","colab_type":"code","colab":{}},"source":["from datetime import date, timedelta, time, datetime\n","\n","def to_datetime(x): \n","  li = x.split()\n","  my_date = li[0].split(\"-\")\n","  my_time = li[1].split(\":\")\n","\n","  ret = datetime(int(my_date[0]), int(my_date[1]), int(my_date[2]), int(my_time[0]), int(my_time[1]), int(my_time[2]))\n","  \n","  return ret\n","\n","age_at_admission = dict()  \n","birth_date = dict()\n","admit_date = dict() \n","for _, row in patients.iterrows(): \n","  birth_date[row.SUBJECT_ID] = to_datetime(row.DOB)\n","\n","for _, row in admissions.iterrows(): \n","  admit_date[row.SUBJECT_ID] = to_datetime(row.ADMITTIME)\n","  age_at_admission[row.SUBJECT_ID] = to_datetime(row.ADMITTIME) - birth_date[row.SUBJECT_ID]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a-Fl9r0TTcp","colab_type":"code","colab":{}},"source":["# Time since admission (hours)\n","def normalize_time(patient_id, x): \n","  delta = to_datetime(x) - admit_date[patient_id]\n","  return delta.total_seconds() / 3600.0 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rL1DdpvVh5q","colab_type":"code","colab":{}},"source":["patient_set = set([p for p in patients.SUBJECT_ID])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ss7GMc9FCcOE","colab_type":"code","colab":{}},"source":["chartevents['HOURS_IN'] = chartevents.apply(lambda row: normalize_time(row.SUBJECT_ID, row.CHARTTIME), axis=1)\n","lab_events['HOURS_IN'] = lab_events.apply(lambda row: normalize_time(row.SUBJECT_ID, row.CHARTTIME), axis=1)\n","surgery_vital_signs['HOURS_IN'] = surgery_vital_signs.apply(lambda row: normalize_time(row.SUBJECT_ID, row.MONITORTIME), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIPVoy9_7HS3","colab_type":"code","colab":{}},"source":["def get_feature_name(idx): \n","  if idx < (len(lab_feats)): \n","    return lab_item_dict[lab_feats[idx]]\n","  elif idx < (len(lab_feats) + len(chart_feats)): \n","    return item_dict[chart_feats[idx - len(lab_feats)]]\n","  elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats)): \n","    return item_dict[surgery_feats[idx - len(lab_feats) - len(chart_feats)]]\n","  elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats) + 2):\n","    return 'gender'\n","  else: \n","    return 'age'\n","\n","def get_feature_name_flattened(idx): \n","  hours_in = idx // (len(lab_feats) + len(chart_feats) + len(surgery_feats))\n","\n","  idx -= hours_in * (len(lab_feats) + len(chart_feats) + len(surgery_feats))\n","\n","  if hours_in == WINDOW_SIZE: \n","    if idx < 2: \n","      return 'gender'\n","    else: \n","      return 'age'\n","  else: \n","    if idx < (len(lab_feats)): \n","      return lab_item_dict[lab_feats[idx]]\n","    elif idx < (len(lab_feats) + len(chart_feats)): \n","      return item_dict[chart_feats[idx - len(lab_feats)]]\n","    elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats)): \n","      return item_dict[surgery_feats[idx - len(lab_feats) - len(chart_feats)]]\n","\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XlhXYs49KhC","colab_type":"code","colab":{}},"source":["import math \n","## Feature Set\n","\n","## Chart Features\n","chart_feats = ['1001', '1002', '1003', '1004', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016']\n","\n","\n","# Surgery Vital Signs\n","surgery_feats = surgery_vital_signs['ITEMID'].value_counts().index.tolist() \n","\n","lab_feats = [5225, \n","             5097, \n","             5141, \n","             5129, \n","             5257, \n","             5114,\n","             5113,\n","             5115,\n","             5132,\n","             5136,\n","             5226,\n","             5230,\n","             5218,\n","             5224,\n","             5212,\n","             5033,\n","             5041,\n","             5223,\n","             5215,\n","             5174,\n","             5111,\n","             6317,\n","             5094,\n","             5492,\n","             5002,\n","             5075,\n","             5237,\n","             5249,\n","             5235,\n","             5239,\n","             5227,\n","             5026,\n","             5031,\n","             5024,\n","             6085\n","             ]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OSCoo8grlA9s","colab_type":"text"},"source":["We use these to index into the tensors that follow (i.e. chart_X[patient_index_of[subject_id]] is what you want, not chart_X[subject_id]. Similar for item_id's"]},{"cell_type":"code","metadata":{"id":"YObWSqyhOK7B","colab_type":"code","colab":{}},"source":["# More Helper Dicts\n","chart_index_of = dict() \n","for i in range(len(chart_feats)): \n","  chart_index_of[chart_feats[i]] = i\n","  \n","lab_index_of = dict() \n","for i in range(len(lab_feats)): \n","  lab_index_of[lab_feats[i]] = i\n","\n","surgery_index_of = dict() \n","for i in range(len(surgery_feats)): \n","  surgery_index_of[surgery_feats[i]] = i\n","\n","\n","print(chart_index_of)\n","print(lab_index_of)\n","print(surgery_index_of)\n","\n","patient_index_of = dict() \n","cc = 0\n","for p in patient_set: \n","  patient_index_of[p] = cc \n","  cc += 1\n","  \n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0ijOJ0O8Y7Z","colab_type":"code","colab":{}},"source":["GAP_TIME          = 6  # In hours\n","WINDOW_SIZE       = 24 # Data collection window: In hours\n","# Label has to be first satisfied after GAP_TIME + WINDOW_SIZE\n","\n","# Generate per-hour aggregates (w/in the window).\n","\n","chart_X = np.zeros((len(patient_set), WINDOW_SIZE, len(chart_feats)))\n","chart_Xcnt = np.zeros((len(patient_set), WINDOW_SIZE, len(chart_feats)))\n","lab_X = np.zeros((len(patient_set), WINDOW_SIZE, len(lab_feats)))\n","lab_Xcnt = np.zeros((len(patient_set), WINDOW_SIZE, len(lab_feats)))\n","surgery_X = np.zeros((len(patient_set), WINDOW_SIZE, len(surgery_feats)))\n","surgery_Xcnt = np.zeros((len(patient_set), WINDOW_SIZE, len(surgery_feats)))\n","\n","# Remove negative chart times\n","subjects_to_remove = set() \n","\n","def is_number(s):\n","    try:\n","        float(s)\n","        return True\n","    except ValueError:\n","        return False\n","\n","for _, row in lab_events[lab_events['HOURS_IN'] < WINDOW_SIZE][lab_events['ITEMID'].isin(lab_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","  elif is_number(row.VALUE): \n","    lab_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][lab_index_of[row.ITEMID]] += row.VALUENUM\n","    lab_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][lab_index_of[row.ITEMID]] += 1 \n","\n","for _, row in surgery_vital_signs[surgery_vital_signs['HOURS_IN'] < WINDOW_SIZE][surgery_vital_signs['ITEMID'].isin(surgery_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","  elif is_number(row.VALUE): \n","    surgery_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][surgery_index_of[row.ITEMID]] += row.VALUE\n","    surgery_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][surgery_index_of[row.ITEMID]] += 1 \n","\n","for _, row in chartevents[chartevents['HOURS_IN'] < WINDOW_SIZE][chartevents['ITEMID'].isin(chart_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","    continue \n","  elif is_number(row.VALUE): \n","    chart_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][chart_index_of[row.ITEMID]] += row.VALUENUM \n","    chart_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][chart_index_of[row.ITEMID]] += 1 \n","\n","for _, row in admissions.iterrows(): \n","  if normalize_time(row.SUBJECT_ID, row.DISCHTIME) < (GAP_TIME + WINDOW_SIZE): \n","    subjects_to_remove.add(row.SUBJECT_ID)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dc_Ci_sxEYny","colab_type":"text"},"source":["Here I have simple Forward/Backward Imputation implemented. If time, we can try to implement the various other ones mentioned by https://www.nature.com/articles/s41598-018-24271-9 \n","\n","global_mean is the mean of each feature over all time points and all patients. If a patient has no occurances of a feature at any time point, it's replaced by the global mean. Otherwise, we propagate values forward/backward to replace missing values. "]},{"cell_type":"code","metadata":{"id":"OkniVeTbV3t6","colab_type":"code","colab":{}},"source":["# Missing Data Imputation\n","\n","# Forward/Backward Imputation\n","\n","# Compute Global means first. \n","\n","global_chart_mean = np.zeros(len(chart_feats))\n","global_chart_num = np.zeros(len(chart_feats))\n","global_lab_mean = np.zeros(len(lab_feats)) \n","global_lab_num = np.zeros(len(lab_feats)) \n","global_surgery_mean = np.zeros(len(surgery_feats))\n","global_surgery_num = np.zeros(len(surgery_feats))\n","\n","for i in range(len(patient_set)): \n","  for j in range(WINDOW_SIZE): \n","    for k in range(len(chart_feats)): \n","      global_chart_mean[k] += chart_X[i][j][k]\n","      global_chart_num[k] += chart_Xcnt[i][j][k] \n","    for k in range(len(lab_feats)): \n","      global_lab_mean[k] += lab_X[i][j][k]\n","      global_lab_num[k] += lab_Xcnt[i][j][k] \n","    for k in range(len(surgery_feats)): \n","      global_surgery_mean[k] += surgery_X[i][j][k] \n","      global_surgery_num[k] += surgery_Xcnt[i][j][k] \n","\n","for k in range(len( chart_feats)): \n","  global_chart_mean[k] = global_chart_mean[k] / global_chart_num[k]\n","\n","for k in range(len(lab_feats)): \n","  global_lab_mean[k] = global_lab_mean[k] / global_lab_num[k]\n","\n","for k in range(len(surgery_feats)): \n","  global_surgery_mean[k] = global_surgery_mean[k] / global_surgery_num[k]\n","\n","\n","def forward_backward_impute(feats, global_mean): \n","  # INPUTS: \n","  # Feats -- (WINDOW_SIZE, num_feats)\n","  # glboal_mean -- (num_feats)\n","  # OUTPUTS: \n","  # ret -- (WINDOW_SIZE, num_feats) (imputed)\n","  ret = feats \n","  for j in range(feats.shape[1]):\n","    for i in range(1, WINDOW_SIZE): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = ret[i-1][j]\n","    for i in range(WINDOW_SIZE-2, -1, -1): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = ret[i+1][j]\n","    for i in range(WINDOW_SIZE): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = global_mean[j]\n","  return ret \n","\n","\n","\n","\n","\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkRov0eLbCnr","colab_type":"code","colab":{}},"source":["# Set up X, Y \n","\n","\n","# Set up labels\n","\n","patient_set = list(patient_set)\n","\n","mort_icu = dict() \n","for _, row in patients.iterrows(): \n","  if row.SUBJECT_ID in patient_set: \n","    mort_icu[row.SUBJECT_ID] = row.EXPIRE_FLAG \n","\n","gender_one_hot = np.zeros((len(patient_set), 2))\n","age_vec = np.zeros((len(patient_set), 1))\n","for _, row in patients.iterrows(): \n","  if row.SUBJECT_ID in patient_set: \n","    age_vec[patient_index_of[row.SUBJECT_ID]][0] = (age_at_admission[row.SUBJECT_ID].total_seconds() / 3600.0)\n","    if row.GENDER == 'M': \n","      gender_one_hot[patient_index_of[row.SUBJECT_ID]][0] = 1\n","    else: \n","      gender_one_hot[patient_index_of[row.SUBJECT_ID]][1] = 1\n","\n","static_vec = np.concatenate((gender_one_hot, age_vec), axis = 1)\n","# [num_patients, 3]\n","\n","chart_vec = chart_X / (chart_Xcnt + (chart_Xcnt == 0))\n","lab_vec = lab_X / (lab_Xcnt + (lab_Xcnt == 0))\n","surgery_vec = surgery_X / (surgery_Xcnt + (surgery_Xcnt == 0))\n","\n","for i in range(len(patient_set)): \n","  chart_vec[i] = forward_backward_impute(chart_vec[i], global_chart_mean)\n","  lab_vec[i] = forward_backward_impute(lab_vec[i], global_lab_mean)\n","  surgery_vec[i] = forward_backward_impute(surgery_vec[i],  global_surgery_mean)\n","\n","time_vec = np.concatenate((lab_vec, chart_vec, surgery_vec), axis=2)\n","# time_vec [num_patients, window_size, num_lab_features + num_chart_features + num_vital_features]\n","\n","# concatenate this with static_vec [num_patients, 3]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"szGv-3ppjq9L","colab_type":"code","colab":{}},"source":["def get_mask(removed_subjects): \n","\n","  mask = [True for p in patient_set]\n","  for p in removed_subjects:\n","    mask[patient_index_of[p]] = False\n","\n","  return mask \n","\n","def setup_data(task, model):\n","  my_subjects_to_remove = subjects_to_remove\n","  if task == 'Sepsis Prediction': \n","\n","    # Protect against labels found in the range [0, WINDOW_SIZE + GAP]. Remove these patients.\n","\n","    for _, row in admissions.iterrows(): \n","      if row.SUBJECT_ID in SEPTIC: \n","        if SEPTIC[row.SUBJECT_ID] < (GAP_TIME + WINDOW_SIZE): \n","          my_subjects_to_remove.add(row.SUBJECT_ID)\n","\n","    # Masks\n","\n","    mask = get_mask(my_subjects_to_remove)\n","\n","    # Labels \n","\n","    labels = np.zeros(len(patient_set)) \n","    for i in range(len(patient_set)): \n","      if patient_set[i] in SEPTIC: \n","        labels[i] = 1\n","      else: \n","        labels[i] = 0\n","      \n","    # Covariates\n","    if model in ['LR', 'RF']: # Linear models\n","      covars = np.concatenate((np.reshape((time_vec), (time_vec.shape[0], time_vec.shape[1] * time_vec.shape[2])), static_vec), axis = 1)\n","      \n","      return covars[mask, ...], labels[mask, ...]\n","\n","    else: # Time series models\n","\n","      # expands labels to (num_patients, window_size) from (num_patients)\n","      labels_ts = torch.from_numpy(labels[mask, ...])\n","      labels_ts = labels_ts.unsqueeze(1).expand((time_vec[mask, ...].shape[0], time_vec[mask, ...].shape[1]))\n","\n","      time_ts = torch.from_numpy(time_vec).float()\n","      static_ts = torch.from_numpy(static_vec).float().unsqueeze(1).expand((time_ts.shape[0], time_ts.shape[1], static_vec.shape[1]))\n","      covars_ts = torch.cat((time_ts, static_ts), dim=2)\n","      covars_ts = covars_ts[mask, ...]\n","\n","      return covars_ts, labels_ts\n","    \n","  elif task == 'Mortality Prediction': \n","    # No need to protect against labels in the range [0, Window + Gap] (all labels are found at discharge time).\n","\n","    # Masks \n","\n","    mask = get_mask(my_subjects_to_remove)\n","\n","    # Labels \n","\n","    labels = np.zeros(len(patient_set)) \n","    for i in range(len(patient_set)): \n","      if mort_icu[patient_set[i]] == 1:\n","        labels[i] = 1\n","      else: \n","        labels[i] = 0\n","      \n","    # Covariates\n","    if model in ['LR', 'RF']: # Linear models\n","      covars = np.concatenate((np.reshape((time_vec), (time_vec.shape[0], time_vec.shape[1] * time_vec.shape[2])), static_vec), axis = 1)\n","      \n","      return covars[mask, ...], labels[mask, ...]\n","    else: # Time series models\n","      labels_ts = torch.from_numpy(labels[mask, ...]).float()\n","      labels_ts = labels_ts.unsqueeze(1).expand((time_vec[mask, ...].shape[0], time_vec[mask, ...].shape[1]))\n","\n","      time_ts = torch.from_numpy(time_vec).float()\n","      static_ts = torch.from_numpy(static_vec).float().unsqueeze(1).expand((time_ts.shape[0], time_ts.shape[1], static_vec.shape[1]))\n","      covars_ts = torch.cat((time_ts, static_ts), dim=2)\n","      covars_ts = covars_ts[mask, ...]\n","\n","      return covars_ts, labels_ts\n","\n","  else: \n","    return 0, 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y0LyoBbValp-","colab_type":"code","colab":{}},"source":["from sklearn.metrics import roc_curve\n","def plot_roc(title, labels, probs): \n","  fpr, tpr, thresholds = roc_curve(labels, probs) \n","  plt.figure()\n","  plt.plot(fpr, tpr, label=title)\n","  plt.plot([0, 1], [0, 1],'r--')\n","  plt.xlim([0.0, 1.0])\n","  plt.ylim([0.0, 1.05])\n","  plt.xlabel('1 - Specificity')\n","  plt.ylabel('Sensitivity')\n","  plt.title('ROC')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MHdEiweyE1aA","colab_type":"text"},"source":["RF Helper Funcs"]},{"cell_type":"code","metadata":{"id":"dO2_0Lgqter7","colab_type":"code","colab":{}},"source":["\n","# X [num_patients, WINDOW_SIZE, num_features] (for LSTM)\n","# X [num_patients, WINDOW_SIZE * num_features] (for RF) \n","# Y [num_patients, WINDOW_SIZE] (for LSTM) \n","# Y [num_patients] (for RF)\n","\n","from sklearn.model_selection import KFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","def train_rf(task, imbalanced=False, n_estimators=100, bootstrap=True, max_features='sqrt'): \n","  X, Y = setup_data(task = task, model = 'RF')\n","\n","  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n","  x_test_orig = x_test\n","\n","  my_scaler = StandardScaler()\n","\n","  x_train = my_scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n","  x_test = my_scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n","  \n","  if imbalanced: \n","    x_train, y_train = oversample(x_train, y_train)\n","\n","  model = RandomForestClassifier(n_estimators=n_estimators, \n","                             bootstrap = bootstrap,\n","                             max_features = max_features)\n","  model.fit(x_train, y_train)\n","\n","  return model, x_test, y_test, x_test_orig\n","\n","def evaluate_rf(model, x_test, y_test, mask): \n","\n","  x_test = x_test[mask, ...]\n","  y_test = y_test[mask, ...]\n","\n","  rf_predictions = model.predict(x_test)\n","  rf_probs = model.predict_proba(x_test)[:, 1]\n","\n","  auc = roc_auc_score(y_test, rf_probs)\n","  acc = np.sum(rf_predictions == y_test) / len(y_test)\n","\n","  return auc, acc, rf_predictions, rf_probs \n","\n","def run_task_rf(task): \n","  if task in ['Mortality Prediction', 'Sepsis Prediction']: \n","    model, x_test, y_test, x_test_orig = train_rf(task, imbalanced=True)\n","  else: \n","    model, x_test, y_test, x_test_orig = train_rf(task, imbalanced=False)\n","\n","  all_auc = []\n","  all_acc = []\n","  all_probs = []\n","  all_preds = []\n","  all_labels = []\n","  \n","  cohorts = ['Total', '0 - 2 Month', '2 Month - 2 Years', '2 Years - 5 Years', '5 Years - 12 Years']\n","  threshs = [-1, 60 * 24, 2 * 365 * 24, 5 * 365 * 24, 12 *  365 * 24]\n","\n","  mask = [True for p in range(len(x_test))]\n","  for i in range(len(threshs)): \n","    if i == 0: \n","      mask = [True for p in range(len(x_test))]\n","    else: \n","      for p in range(len(x_test)): \n","        mask[p] = True\n","        age = x_test_orig[p][-1]\n","        if (age <= threshs[i-1]) or (age > threshs[i]): \n","          mask[p] = False\n","  \n","    auc, acc, rf_preds, rf_probs = evaluate_rf(model, x_test, y_test, mask)\n","    all_auc.append(auc)\n","    all_acc.append(acc)\n","    all_probs.append(rf_probs)\n","    all_preds.append(rf_preds)\n","    all_labels.append(y_test[mask, ...])\n","\n","  return cohorts, all_auc, all_acc, all_probs, all_preds, all_labels\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJvE4q8_5iM-","colab_type":"code","colab":{}},"source":["cohorts, all_auc, all_acc, all_probs, all_preds, all_labels = run_task_rf('Mortality Prediction')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJyrg6aqNB_r","colab_type":"code","colab":{}},"source":["print(cohorts) \n","print(all_auc)\n","print(all_acc)\n","print([len(all_labels[i]) for i in range(len(all_labels))])\n","print([np.sum(all_labels[i]) for i in range(len(all_labels))])\n","\n","#['Total', '0 - 1 Week', '<1 Week - 1 Month', '<1 Month - 1 Year', '1 Year - 5 Years', '5 Years - 12 Years', '12 Years - 18 Years']\n","#[0.8171612386874347, 0.6792912408061897, 0.813731722822632, 0.8320398009950248, 0.8785932925206281, 0.7720345640219952, 0.8766666666666666]\n","#[0.9056764831412719, 0.9102564102564102, 0.9025974025974026, 0.8835616438356164, 0.9221854304635762, 0.9067796610169492, 0.941747572815534]\n","#[2343, 390, 154, 730, 604, 354, 103]\n","#[148.0, 29.0, 11.0, 60.0, 26.0, 19.0, 3.0]\n","\n","plt.title('RF ROC Curves')\n","for i in range(len(cohorts)): \n","  fpr, tpr, thresholds = roc_curve(all_labels[i], all_probs[i])\n","  plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (cohorts[i], all_auc[i]))\n","\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('1-Specificity')\n","plt.ylabel('Sensitivity')\n","plt.legend(loc=\"lower right\")\n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnnolY1UxTOA","colab_type":"code","colab":{}},"source":["class LSTM_Classifier(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers=1, dropout=0., bidirectional=False):\n","    super(LSTM_Classifier, self).__init__()\n","\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers \n","    self.bidirectional = bidirectional\n","    self.dropout = dropout\n","\n","    self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True,\n","                      dropout=dropout, bidirectional=bidirectional)\n","    self.out = nn.Linear(hidden_size + hidden_size * int(bidirectional), 1)\n","\n","  def forward(self, input):\n","    # Input is (1, seq_len, input_size)\n","    rnn_out, _ = self.rnn(input)\n","    # rnn_out is (1, seq_len, directions * hidden_size)\n","    # output is (1, seq_len, 1)\n","    return self.out(rnn_out)\n","\n","def rnn_train_one_sample(model, criterion, rnn_optimizer, sent_tensor, tag_tensor, alpha = 0.5, clip=None):\n","\n","    # sent_tensor is (Num Hours, Num feats)\n","    # tag_tensor is (Num Hours)\n","\n","    model.zero_grad() \n","\n","    outputs = model(sent_tensor.unsqueeze(0)).squeeze(2).squeeze(0)\n","\n","    # loss = criterion(outputs, tag_tensor) * alpha + criterion(outputs[-1], tag_tensor[-1]) * (1.0-alpha)\n","    loss = criterion(outputs[-1], tag_tensor[-1]) \n","\n","    loss.backward()\n","\n","    if clip != None: \n","      torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=clip)\n","\n","    rnn_optimizer.step()\n","\n","    return outputs, loss.item()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jhgk4icHmNFz","colab_type":"code","colab":{}},"source":["import time\n","import math\n","import sklearn\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def evaluate_result(true_tag_list, predicted_tag_list, probs):\n","  return np.mean(true_tag_list.numpy() == predicted_tag_list), roc_auc_score(true_tag_list, probs)\n","\n","# Make prediction for one sentence.\n","def rnn_predict_one_sent(model, sent_tensor):\n","  \n","    outputs = model(sent_tensor.unsqueeze(0)).squeeze(2).squeeze(0)\n","    prob = torch.sigmoid(outputs[-1])\n","\n","    predicted_tag_id = 0\n","    if prob > 0.5: \n","      predicted_tag_id = 1\n","    \n","    return predicted_tag_id, prob.item()\n","\n","\n","def evaluate_rnn(model, x_test, y_test, mask = None): \n","  if mask == None: \n","    mask = [True for i in range(len(x_test))]\n","  x_test = torch.from_numpy(x_test).float()\n","  x_test = x_test[mask, ...]\n","  y_test = y_test[mask, ...]\n","\n","  model.eval()\n","  predicted_tags = []\n","  probs = []\n","\n","  for i in range(len(x_test)): \n","    sent_tensor = x_test[i]\n","    sent_tensor = sent_tensor.to(device)\n","    predicted_tag_id, prob = rnn_predict_one_sent(model, sent_tensor)\n","    predicted_tags.append(predicted_tag_id)\n","    probs.append(prob)\n","\n","  acc, auc = evaluate_result(y_test[:, -1], predicted_tags, probs)\n","\n","  return auc, acc, predicted_tags, probs \n","\n","def train_model(model, criterion, optimizer, X_train, Y_train, X_test, Y_test, n_epochs=5, print_every=1000, plot_every=50, learning_rate=1e-3, alpha = 0.5, clip=None): \n","\n","  iter_count = 0\n","\n","  current_loss = 0\n","  current_norm = 0\n","  all_losses = []\n","  all_norms = []\n","\n","  start = time.time()\n","\n","  model.train()\n","  for epoch_i in range(n_epochs):\n","\n","    for i in range(X_train.shape[0]): \n","        sent_tensor = torch.tensor(X_train[i]).float()\n","        tag_tensor = Y_train[i]\n","\n","        sent_tensor = sent_tensor.to(device)\n","        tag_tensor = tag_tensor.to(device)\n","  \n","        output, loss = rnn_train_one_sample(model, criterion, optimizer, sent_tensor, tag_tensor, alpha=alpha, clip=clip)\n","        current_loss += loss\n","\n","        if iter_count % print_every == 0:\n","            print('%d %s %.4f' % (iter_count, timeSince(start), current_loss / print_every))\n","            current_loss = 0\n","\n","        iter_count += 1\n","\n","    auc, acc, _, _ = evaluate_rnn(model, X_test, Y_test)\n","    print(\"Epoch \", epoch_i, \" ACC of \", acc, \" AUC of \", auc)\n","  return all_losses, all_norms\n","\n","def plot_losses(losses): \n","  plt.figure()\n","  plt.title('Losses vs Iterations')\n","  plt.plot(losses)\n","  plt.show()\n","\n","def plot_norms(norms): \n","  plt.figure()\n","  plt.title('Norms vs Iterations')\n","  plt.plot(norms)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JWmp142J7Qnm","colab_type":"text"},"source":["Helpers with evaluation. We should tune these hyperparameters. In particular I set n_epochs to 2 because I just wanted to know that it works kinda :p"]},{"cell_type":"code","metadata":{"id":"b_sjaOKT1q85","colab_type":"code","colab":{}},"source":["# Evaluation\n","\n","def train_rnn(task, imbalanced=False, \n","              n_epochs=10, \n","              rnn_clip = 1.0, \n","              rnn_hidden_size = 32, \n","              rnn_num_layers = 2, \n","              learning_rate = 1e-4, \n","              rnn_dropout = 0.5, \n","              rnn_alpha = 0.5, \n","              weight_decay = 1e-4,\n","              rnn_bidirectional = False): \n","\n","  X, Y = setup_data(task = task, model = 'LSTM')\n","  \n","  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n","  x_test_orig = x_test\n","\n","  scaler = StandardScaler()\n","\n","  x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n","  x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n","\n","  if imbalanced: \n","    x_train = torch.from_numpy(x_train).float()\n","    x_train = torch.reshape(x_train, (x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n","    y_train = y_train[:, -1]\n","\n","    x_train, y_train = oversample(x_train, y_train)\n","\n","    x_train = torch.from_numpy(x_train).float()\n","    x_train = x_train.reshape(x_train.shape[0], WINDOW_SIZE, (int)(x_train.shape[1] / WINDOW_SIZE))\n","    y_train = torch.from_numpy(y_train).float()\n","    y_train = y_train.unsqueeze(1).expand((y_train.shape[0], WINDOW_SIZE))\n","\n","  num_feats = x_train.shape[2]\n","\n","  rnn_model = LSTM_Classifier(input_size=num_feats, hidden_size=rnn_hidden_size, num_layers=rnn_num_layers, dropout=rnn_dropout, bidirectional=rnn_bidirectional)\n","  criterion = nn.BCEWithLogitsLoss()\n","  rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","  losses, norms = train_model(rnn_model, criterion, rnn_optimizer, x_train, y_train, x_test, y_test, n_epochs=n_epochs, alpha=rnn_alpha, clip=rnn_clip)\n","\n","  return rnn_model, x_test, y_test, x_test_orig\n","\n","def run_task_lstm(task): \n","  if task in ['Sepsis Prediction']: \n","    model, x_test, y_test, x_test_orig = train_rnn(task, imbalanced=True, n_epochs=40)\n","  else: \n","    model, x_test, y_test, x_test_orig = train_rnn(task, imbalanced=False, n_epochs=40)\n","\n","  all_auc = []\n","  all_acc = []\n","  all_probs = []\n","  all_preds = []\n","  all_labels = []\n","\n","  cohorts = ['Total', '0 - 2 Month', '2 Month - 2 Years', '2 Years - 5 Years', '5 Years - 12 Years']\n","  threshs = [-1, 60 * 24, 2 * 365 * 24, 5 * 365 * 24, 12 *  365 * 24]\n","\n","  mask = [True for p in range(len(x_test))]\n","  for i in range(len(threshs)): \n","    if i == 0: \n","      mask = [True for p in range(len(x_test))]\n","    else: \n","      for p in range(len(x_test)): \n","        mask[p] = True\n","        age = x_test_orig[p][-1][-1]\n","        if (age <= threshs[i-1]) or (age > threshs[i]): \n","          mask[p] = False\n","\n","    auc, acc, rf_preds, rf_probs = evaluate_rnn(model, x_test, y_test, mask)\n","    all_auc.append(auc)\n","    all_acc.append(acc)\n","    all_probs.append(rf_probs)\n","    all_preds.append(rf_preds)\n","    all_labels.append(y_test[mask, ...][:, -1])\n","\n","  return cohorts, all_auc, all_acc, all_probs, all_preds, all_labels\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SId853IVZLSx","colab_type":"text"},"source":["Set up data and evaluate."]},{"cell_type":"code","metadata":{"id":"L9nQknnDRm9E","colab_type":"code","colab":{}},"source":["cohorts, all_auc, all_acc, all_probs, all_preds, all_labels = run_task_lstm('Mortality Prediction')\n","print(cohorts) \n","print(all_auc)\n","print(all_acc)\n","print([len(all_labels[i]) for i in range(len(all_labels))])\n","print([torch.sum(all_labels[i]).item() for i in range(len(all_labels))])\n","\n","plt.title('RF ROC Curves')\n","for i in range(len(cohorts)): \n","  fpr, tpr, thresholds = roc_curve(all_labels[i], all_probs[i])\n","  plt.plot(fpr, tpr, label='%s ROC (area = %0.2f)' % (cohorts[i], all_auc[i]))\n","\n","plt.plot([0, 1], [0, 1],'r--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('1-Specificity')\n","plt.ylabel('Sensitivity')\n","plt.legend(loc=\"lower right\")\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7OCEuztJY6Fy","colab_type":"text"},"source":["Previous Versions."]},{"cell_type":"code","metadata":{"id":"ma-yNTA3Y4y3","colab_type":"code","colab":{}},"source":["def train_and_evaluate(X_train, Y_train, X_test, Y_test): \n","  num_feats = X_train.shape[2]\n","\n","  # Hyperparams\n","  rnn_clip = 1.0\n","  rnn_hidden_size = 128\n","  rnn_num_layers = 2\n","  learning_rate = 1e-3\n","  rnn_dropout = 0.5\n","  rnn_bidirectional = False\n","  rnn_alpha = 0.5\n","\n","  rnn_model = LSTM_Classifier(input_size=num_feats, hidden_size=rnn_hidden_size, num_layers=rnn_num_layers, dropout=rnn_dropout, bidirectional=rnn_bidirectional)\n","  criterion = nn.BCEWithLogitsLoss()\n","  rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate)\n","  ### Train\n","  losses, norms =  train_model(rnn_model, criterion, rnn_optimizer, X_train, Y_train, n_epochs=10, alpha=rnn_alpha, clip=rnn_clip)\n","\n","  ### Test\n","  rnn_model.eval()\n","  predicted_tags = []\n","  probs = []\n","\n","  for i in range(len(X_test)): \n","    sent_tensor = torch.tensor(X_test[i]).float()\n","    sent_tensor = sent_tensor.to(device)\n","    predicted_tag_id, prob = rnn_predict_one_sent(rnn_model, sent_tensor)\n","    predicted_tags.append(predicted_tag_id)\n","    probs.append(prob)\n","\n","  acc, auc = evaluate_result(Y_test[:, -1], predicted_tags, probs)\n","  \n","  return auc, acc, probs, rnn_model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"39IM8L9jZFPq","colab_type":"code","colab":{}},"source":["\n","  \n","X, Y = setup_data(task = 'Mortality Prediction', model = 'LSTM')\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n","\n","scaler = StandardScaler()\n","\n","x_train = scaler.fit_transform(x_train.reshape(-1, x_train.shape[-1])).reshape(x_train.shape)\n","x_test = scaler.transform(x_test.reshape(-1, x_test.shape[-1])).reshape(x_test.shape)\n","\n","x_train = torch.from_numpy(x_train).float()\n","x_train = torch.reshape(x_train, (x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n","y_train = y_train[:, -1]\n","\n","x_train, y_train = oversample(x_train, y_train)\n","\n","x_train = torch.from_numpy(x_train).float()\n","x_train = x_train.reshape(x_train.shape[0], WINDOW_SIZE, (int)(x_train.shape[1] / WINDOW_SIZE))\n","y_train = torch.from_numpy(y_train).float()\n","y_train = y_train.unsqueeze(1).expand((y_train.shape[0], WINDOW_SIZE))\n","\n","auc, acc, probs, model = train_and_evaluate(x_train, y_train, torch.from_numpy(x_test).float(), y_test)\n","\n","print(\"AUC of \", auc)\n","print(\"ACC of \", acc)\n","\n","plot_roc('LSTM Mortality Prediction', y_test[:, -1], probs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZnMU1xMmHY9B","colab_type":"code","colab":{}},"source":["model.eval()\n","# x_test = torch.from_numpy(x_test).float()\n","predicted_tags = []\n","probs = []\n","\n","for i in range(len(x_test)): \n","  sent_tensor = x_test[i]\n","  sent_tensor = sent_tensor.to(device)\n","  predicted_tag_id, prob = rnn_predict_one_sent(model, sent_tensor)\n","  predicted_tags.append(predicted_tag_id)\n","  probs.append(prob)\n","\n","print(predicted_tags) \n","print(y_test[:, -1])\n","print(probs)\n","acc, auc = evaluate_result(y_test[:, -1], predicted_tags, probs)\n","\n","print(\"AUC of \", auc)\n","print(\"ACC of \", acc)\n","\n","plot_roc('LSTM Mortality Prediction', y_test[:, -1], probs)"],"execution_count":0,"outputs":[]}]}