{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Rolling Baselines (Lab Tests)","provenance":[{"file_id":"1gz_2CkgC8ZzKfttcO8pi5LbFXeuCT_wt","timestamp":1589099343557},{"file_id":"1xCVo8S3Pz_x-4yleF_MkRWNGzw2SslTf","timestamp":1588019404982},{"file_id":"1WDTWvfZvIrcclqAs5KMqEroQ5rtaB3yJ","timestamp":1587625813876},{"file_id":"1Jxj3hQ5pSST0KmnFG2TKUslG-00eFMWc","timestamp":1583092405360},{"file_id":"19tSvuHLZ3fawJk4_72YhU3xtLJ3FOAWd","timestamp":1582605945703},{"file_id":"1AOw9OTa6m6jEC9RBsWyWPOBdVjBcSjQQ","timestamp":1582513757775}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"sBEzAm_FGp8v","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils import data\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import pandas as pd\n","%matplotlib inline\n","from matplotlib import pyplot as plt\n","\n","import numpy as np\n","import pickle\n","\n","from google.colab import auth\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"khpk-ADtGvmk","colab_type":"code","colab":{}},"source":["!wget -r -N -c -np --user nhulkund --ask-password https://physionet.org/files/picdb/1.0.0/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"363L7jzp6zz3","colab_type":"code","colab":{}},"source":["# Read Data into DF\n","\n","admissions = pd.read_csv('physionet.org/files/picdb/1.0.0/ADMISSIONS.csv.gz', compression='gzip')\n","chartevents = pd.read_csv('physionet.org/files/picdb/1.0.0/CHARTEVENTS.csv.gz', compression='gzip')\n","diagnoses_icd = pd.read_csv('physionet.org/files/picdb/1.0.0/DIAGNOSES_ICD.csv.gz', compression='gzip')\n","d_icd_diagnoses = pd.read_csv('physionet.org/files/picdb/1.0.0/D_ICD_DIAGNOSES.csv.gz', compression='gzip')\n","d_items = pd.read_csv('physionet.org/files/picdb/1.0.0/D_ITEMS.csv.gz', compression='gzip')\n","d_labitems = pd.read_csv('physionet.org/files/picdb/1.0.0/D_LABITEMS.csv.gz', compression='gzip')\n","emr_symptoms = pd.read_csv('physionet.org/files/picdb/1.0.0/EMR_SYMPTOMS.csv.gz', compression='gzip')\n","icu_stays = pd.read_csv('physionet.org/files/picdb/1.0.0/ICUSTAYS.csv.gz', compression='gzip')\n","input_events = pd.read_csv('physionet.org/files/picdb/1.0.0/INPUTEVENTS.csv.gz', compression='gzip')\n","lab_events = pd.read_csv('physionet.org/files/picdb/1.0.0/LABEVENTS.csv.gz', compression='gzip')\n","patients = pd.read_csv('physionet.org/files/picdb/1.0.0/PATIENTS.csv.gz', compression='gzip')\n","prescriptions = pd.read_csv('physionet.org/files/picdb/1.0.0/PRESCRIPTIONS.csv.gz', compression='gzip')\n","surgery_vital_signs = pd.read_csv('physionet.org/files/picdb/1.0.0/SURGERY_VITAL_SIGNS.csv.gz', compression='gzip')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WnpnX6O3QZ-X","colab_type":"code","colab":{}},"source":["d_items_df=pd.DataFrame(d_items)\n","print(d_items['ITEMID'][100:150])\n","d_items['ITEMID']=d_items['ITEMID'].str.replace(\" \",\"\")\n","print(type(d_items.ITEMID[0]))\n","print(d_items.loc[d_items['ITEMID']=='5141'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PdDz95lpKJ6R","colab_type":"code","colab":{}},"source":["# Easier to use: \n","\n","item_dict = dict() \n","for _, row in d_items.iterrows(): \n","  item_dict[row.ITEMID] = row.LABEL\n","\n","lab_item_dict = dict()\n","for _, row in d_labitems.iterrows(): \n","  lab_item_dict[row.ITEMID] = row.LABEL\n","\n","ICD_CN_TO_ICD = dict() \n","for _, row in d_icd_diagnoses.iterrows(): \n","  ICD_CN_TO_ICD[row.ICD10_CODE_CN] = row.ICD10_CODE \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L6oefTPmDrgy","colab_type":"text"},"source":["Here we include only the first admission of each patient."]},{"cell_type":"code","metadata":{"id":"vQI20hqJH2iK","colab_type":"code","colab":{}},"source":["# Clean: Include only the first admission\n","\n","admissions = admissions.sort_values(by = ['ADMITTIME'])\n","\n","admits_to_keep = []\n","seen_patients = set()\n","\n","for _, row in admissions.iterrows(): \n","  if row.SUBJECT_ID not in seen_patients: \n","    admits_to_keep.append(row.HADM_ID)\n","    seen_patients.add(row.SUBJECT_ID)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcz6Z57DMUSI","colab_type":"code","colab":{}},"source":["def remove_admits(df): \n","  return df[df['HADM_ID'].isin(admits_to_keep)]\n","\n","admissions = remove_admits(admissions)\n","chartevents = remove_admits(chartevents)\n","diagnoses_icd = remove_admits(diagnoses_icd)\n","emr_symptoms = remove_admits(emr_symptoms)\n","icu_stays = remove_admits(icu_stays)\n","input_events = remove_admits(input_events)\n","lab_events = remove_admits(lab_events)\n","prescriptions = remove_admits(prescriptions)\n","surgery_vital_signs = remove_admits(surgery_vital_signs)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Rak5HJV5DvfE","colab_type":"text"},"source":["Helper functions to parse admit times."]},{"cell_type":"code","metadata":{"id":"kooUgvMHCTAV","colab_type":"code","colab":{}},"source":["from datetime import date, timedelta, time, datetime\n","\n","def to_datetime(x): \n","  li = x.split()\n","  my_date = li[0].split(\"-\")\n","  my_time = li[1].split(\":\")\n","\n","  ret = datetime(int(my_date[0]), int(my_date[1]), int(my_date[2]), int(my_time[0]), int(my_time[1]), int(my_time[2]))\n","  \n","  return ret\n","\n","age_at_admission = dict()  \n","birth_date = dict()\n","admit_date = dict() \n","for _, row in patients.iterrows(): \n","  birth_date[row.SUBJECT_ID] = to_datetime(row.DOB)\n","\n","for _, row in admissions.iterrows(): \n","  admit_date[row.SUBJECT_ID] = to_datetime(row.ADMITTIME)\n","  age_at_admission[row.SUBJECT_ID] = to_datetime(row.ADMITTIME) - birth_date[row.SUBJECT_ID]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1a-Fl9r0TTcp","colab_type":"code","colab":{}},"source":["# Time since admission (hours)\n","def normalize_time(patient_id, x): \n","  delta = to_datetime(x) - admit_date[patient_id]\n","  return delta.total_seconds() / 3600.0 "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0rL1DdpvVh5q","colab_type":"code","colab":{}},"source":["patient_set = set([p for p in patients.SUBJECT_ID])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ss7GMc9FCcOE","colab_type":"code","colab":{}},"source":["chartevents['HOURS_IN'] = chartevents.apply(lambda row: normalize_time(row.SUBJECT_ID, row.CHARTTIME), axis=1)\n","lab_events['HOURS_IN'] = lab_events.apply(lambda row: normalize_time(row.SUBJECT_ID, row.CHARTTIME), axis=1)\n","surgery_vital_signs['HOURS_IN'] = surgery_vital_signs.apply(lambda row: normalize_time(row.SUBJECT_ID, row.MONITORTIME), axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8XlhXYs49KhC","colab_type":"code","colab":{}},"source":["import math \n","## Feature Set\n","\n","## Chart Features\n","chart_feats = [1001, 1002, 1003, 1004, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016]\n","\n","\n","# Surgery Vital Signs\n","surgery_feats = surgery_vital_signs['ITEMID'].value_counts().index.tolist() \n","\n","\n","lab_feats = [5225, \n","             5097, \n","             #5141, \n","             5129, \n","             5257, \n","             5114,\n","             5113,\n","             5115,\n","             5132,\n","             5136,\n","             5226,\n","             5230,\n","             5218,\n","             5224,\n","             5212,\n","             5033,\n","             5041,\n","             5223,\n","             5215,\n","             5174,\n","             5111,\n","             #6317,\n","             #5094,\n","             #5492,\n","             #5002,\n","             5075,\n","             5237,\n","             5249,\n","             5235,\n","             5239,\n","             5227,\n","             5026,\n","             5031,\n","             5024,\n","             6085\n","             ]\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mKs_inl1cg6U","colab_type":"code","colab":{}},"source":["for id in lab_feats:\n","  print(id,lab_item_dict[id])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VIPVoy9_7HS3","colab_type":"code","colab":{}},"source":["def get_feature_name(idx): \n","  if idx < (len(lab_feats)): \n","    return lab_item_dict[lab_feats[idx]]\n","  elif idx < (len(lab_feats) + len(chart_feats)): \n","    return item_dict[str(chart_feats[idx - len(lab_feats)])]\n","  elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats)): \n","    return item_dict[surgery_feats[idx - len(lab_feats) - len(chart_feats)]]\n","  elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats) + 2):\n","    return 'gender'\n","  else: \n","    return 'age'\n","\n","def get_feature_name_flattened(idx): \n","  hours_in = idx // (len(lab_feats) + len(chart_feats) + len(surgery_feats))\n","\n","  idx -= hours_in * (len(lab_feats) + len(chart_feats) + len(surgery_feats))\n","\n","  if hours_in == WINDOW_SIZE: \n","    if idx < 2: \n","      return 'gender'\n","    else: \n","      return 'age'\n","  else: \n","    if idx < (len(lab_feats)): \n","      return lab_item_dict[lab_feats[idx]]\n","    elif idx < (len(lab_feats) + len(chart_feats)): \n","      return item_dict[str(chart_feats[idx - len(lab_feats)])]\n","    elif idx < (len(lab_feats) + len(chart_feats) + len(surgery_feats)): \n","      return item_dict[surgery_feats[idx - len(lab_feats) - len(chart_feats)]]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gn1nMoCS1byI","colab_type":"code","colab":{}},"source":["def key_fn(tup):\n","  return abs(tup[0])\n","\n","def sort_importance(coefficients, feat_name_fn):\n","  coef_shape = coefficients.shape\n","  print(coef_shape)\n","  importance = []\n","\n","  for i in range(coef_shape[1]):\n","    importance.append((coefficients[0,i], feat_name_fn(i)))\n","    # print('index {} gives {}'.format(i, feat_name_fn(i)))\n","  \n","  return sorted(importance, key=key_fn, reverse=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1R6yhydH1kii","colab_type":"code","colab":{}},"source":["def convert_float_tensor(X):\n","  return torch.tensor(X).float()\n","\n","def perturb_features(model, X, feature_range=None):\n","  if feature_range is None:\n","    feature_range = (0, X.shape[2])\n","\n","  print(feature_range)\n","  perturb_effects = []\n","  tensor_x = convert_float_tensor(X)\n","  orig_out = model(tensor_x)\n","\n","  for ind in range(feature_range[0], feature_range[1]):\n","    variable_name = get_feature_name(ind)\n","    # print(f'Dealing with variable {variable_name}')\n","    perturbation = np.random.normal(0.0, 0.2, size=X.shape[:2])\n","    X[:, :, ind] = X[:, :, ind] + perturbation\n","    effect = ((orig_out - model(convert_float_tensor(X))) ** 2).mean() ** 0.5\n","    print(f'Variable {ind+1} name ({variable_name}), perturbation effect: {effect:.4f}')\n","    perturb_effects.append((effect, variable_name, ind))\n","    X[:, :, ind] = X[:, :, ind] - perturbation\n","  \n","  return sorted(perturb_effects, key=key_fn, reverse=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OSCoo8grlA9s","colab_type":"text"},"source":["We use these to index into the tensors that follow (i.e. chart_X[patient_index_of[subject_id]] is what you want, not chart_X[subject_id]. Similar for item_id's"]},{"cell_type":"code","metadata":{"id":"YObWSqyhOK7B","colab_type":"code","colab":{}},"source":["# More Helper Dicts\n","chart_index_of = dict() \n","for i in range(len(chart_feats)): \n","  chart_index_of[chart_feats[i]] = i\n","  \n","lab_index_of = dict() \n","for i in range(len(lab_feats)): \n","  lab_index_of[lab_feats[i]] = i\n","\n","surgery_index_of = dict() \n","for i in range(len(surgery_feats)): \n","  surgery_index_of[surgery_feats[i]] = i\n","\n","\n","print(chart_index_of)\n","print(lab_index_of)\n","print(surgery_index_of)\n","\n","patient_index_of = dict() \n","cc = 0\n","for p in patient_set: \n","  patient_index_of[p] = cc \n","  cc += 1\n","  \n","  "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vmJzqIgZ01lZ","colab_type":"text"},"source":["# Feature / Label Definition Section"]},{"cell_type":"markdown","metadata":{"id":"bzx7V3vb0lot","colab_type":"text"},"source":["Lets only sample up to 100 hours. That seems reasonable, the whole stay of ~75% of patients are captured here."]},{"cell_type":"code","metadata":{"id":"p7QdQP6rwxfp","colab_type":"code","colab":{}},"source":["MAX_HOURS = 100\n","WINDOW_SIZE = 24\n","GAP_TIME = 6\n","PRED_SIZE = 6"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1fP6f1o1PJn","colab_type":"code","colab":{}},"source":["def is_number(s):\n","    try:\n","        float(s)\n","        return True\n","    except ValueError:\n","        return False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PX9_yGn09PsL","colab_type":"text"},"source":["Here, **feat_val** can be either min, max, or mean depending on the task you want. Change the code beneath it to fit the task. Remember to change the loop to go over lab events of the ID you want. Here, it is the **minimum wbc count** measured over an hour-long window.\n","\n","**feat_cnt** is used to make sure the measurement is made over the prediction interval.\n","\n","**feat_agg** is the label we use in prediction. feat_val[ i ] [ j ] denotes the lab test value for patient i where our window starts at hour j. In other words, it is the aggregate value over hours [j + WINDOW_SIZE + GAP_SIZE, j + WINDOW_SIZE + GAP_TIME + PRED_SIZE). Here, I'm again computing the min. You should change this if you want max/mean/whatever.\n","\n","**window_cnt** is the number of times the test was taken in the desired window. The window is [j + WINDOW_SIZE + GAP_SIZE, j + WINDOW_SIZE + GAP_TIME + PRED_SIZE)"]},{"cell_type":"code","metadata":{"id":"ETiDDaLkXBjq","colab_type":"code","colab":{}},"source":["subjects_to_remove = set() \n","\n","feat_agg = np.zeros((len(patient_set), MAX_HOURS))\n","window_cnt = np.zeros((len(patient_set), MAX_HOURS))\n","\n","feat_val = np.zeros((len(patient_set), MAX_HOURS))\n","feat_cnt = np.zeros((len(patient_set), MAX_HOURS))\n","\n","###\n","def aggregate(x, type):\n","  if type == 'MIN': \n","    return np.min(x)\n","  elif type == 'MAX': \n","    return np.max(x)\n","  else: \n","    return np.mean(x)\n","###\n","\n","###\n","for _, row in lab_events[lab_events['ITEMID'] == 5141][lab_events['HOURS_IN'] < MAX_HOURS].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID) \n","  \n","  elif is_number(row.VALUE): \n","    my_idx = patient_index_of[row.SUBJECT_ID]\n","    my_bkt = int(row.HOURS_IN)\n","\n","    ### \n","    if feat_cnt[my_idx][my_bkt] == 0: \n","      feat_val[my_idx][my_bkt] = row.VALUENUM\n","    else: \n","      feat_val[my_idx][my_bkt] = np.amin([feat_val[my_idx][my_bkt], row.VALUENUM])\n","    ###\n","\n","    feat_cnt[my_idx][my_bkt] += 1\n","###\n","\n","###\n","for i in range(len(patient_set)): \n","  for j in range(MAX_HOURS - WINDOW_SIZE - GAP_TIME - PRED_SIZE):\n","    li = [] \n","    for k in range(j+WINDOW_SIZE+GAP_TIME, j+WINDOW_SIZE+GAP_TIME+PRED_SIZE): \n","      window_cnt[i][j] += feat_cnt[i][k]\n","      if feat_cnt[i][k] > 0: \n","        li.append(feat_val[i][k])\n","    if len(li) > 0: \n","      feat_agg[i][j] = aggregate(np.array(li), type = 'MIN')\n","###"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vf-9m3xmXLuL","colab_type":"text"},"source":["This is just normal stuff."]},{"cell_type":"code","metadata":{"id":"zMtSuIQH1ahG","colab_type":"code","colab":{}},"source":["chart_X = np.zeros((len(patient_set), MAX_HOURS, len(chart_feats)))\n","chart_Xcnt = np.zeros((len(patient_set), MAX_HOURS, len(chart_feats)))\n","lab_X = np.zeros((len(patient_set), MAX_HOURS, len(lab_feats)))\n","lab_Xcnt = np.zeros((len(patient_set), MAX_HOURS, len(lab_feats)))\n","surgery_X = np.zeros((len(patient_set), MAX_HOURS, len(surgery_feats)))\n","surgery_Xcnt = np.zeros((len(patient_set), MAX_HOURS, len(surgery_feats)))\n","\n","for _, row in lab_events[lab_events['HOURS_IN'] < MAX_HOURS][lab_events['ITEMID'].isin(lab_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","  elif is_number(row.VALUE): \n","    lab_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][lab_index_of[row.ITEMID]] += row.VALUENUM\n","    lab_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][lab_index_of[row.ITEMID]] += 1 \n","\n","for _, row in surgery_vital_signs[surgery_vital_signs['HOURS_IN'] < MAX_HOURS][surgery_vital_signs['ITEMID'].isin(surgery_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","  elif is_number(row.VALUE): \n","    surgery_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][surgery_index_of[row.ITEMID]] += row.VALUE\n","    surgery_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][surgery_index_of[row.ITEMID]] += 1 \n","\n","for _, row in chartevents[chartevents['HOURS_IN'] < MAX_HOURS][chartevents['ITEMID'].isin(chart_feats)].iterrows():\n","  if row.HOURS_IN < 0: \n","    subjects_to_remove.add(row.SUBJECT_ID)\n","    continue \n","  elif is_number(row.VALUE): \n","    chart_X[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][chart_index_of[row.ITEMID]] += row.VALUENUM \n","    chart_Xcnt[patient_index_of[row.SUBJECT_ID]][int(row.HOURS_IN)][chart_index_of[row.ITEMID]] += 1 \n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dc_Ci_sxEYny","colab_type":"text"},"source":["Here I have simple Forward/Backward Imputation implemented. If time, we can try to implement the various other ones mentioned by https://www.nature.com/articles/s41598-018-24271-9 \n","\n","global_mean is the mean of each feature over all time points and all patients. If a patient has no occurances of a feature at any time point, it's replaced by the global mean. Otherwise, we propagate values forward/backward to replace missing values. "]},{"cell_type":"code","metadata":{"id":"OkniVeTbV3t6","colab_type":"code","colab":{}},"source":["# Missing Data Imputation\n","\n","# Forward/Backward Imputation\n","\n","# Compute Global means first. \n","\n","global_chart_mean = np.zeros(len(chart_feats))\n","global_lab_mean = np.zeros(len(lab_feats))\n","global_surgery_mean = np.zeros(len(surgery_feats))\n","\n","for k in range(len(chart_feats)): \n","  global_chart_mean[k] = np.sum(chart_X[:, :, k]) / np.sum(chart_Xcnt[:, :, k])\n","for k in range(len(lab_feats)): \n","  global_lab_mean[k] = np.sum(lab_X[:, :, k]) / np.sum(lab_Xcnt[:, :, k])\n","for k in range(len(surgery_feats)):\n","  global_surgery_mean[k] = np.sum(surgery_X[:, :, k]) / np.sum(surgery_Xcnt[:, :, k])\n","\n","\n","def forward_backward_impute(feats, global_mean): \n","  # INPUTS: \n","  # Feats -- (MAX_HOURS, num_feats)\n","  # glboal_mean -- (num_feats)\n","  # OUTPUTS: \n","  # ret -- (MAX_HOURS, num_feats) (imputed)\n","  ret = feats \n","  for j in range(feats.shape[1]):\n","    for i in range(1, MAX_HOURS): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = ret[i-1][j]\n","    for i in range(MAX_HOURS-2, -1, -1): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = ret[i+1][j]\n","    for i in range(MAX_HOURS): \n","      if ret[i][j] <= 0: \n","        ret[i][j] = global_mean[j]\n","  return ret \n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkRov0eLbCnr","colab_type":"code","colab":{}},"source":["# Set up X, Y \n","\n","\n","# Set up labels\n","\n","patient_set = list(patient_set)\n","\n","gender_one_hot = np.zeros((len(patient_set), 2))\n","age_vec = np.zeros((len(patient_set), 1))\n","for _, row in patients.iterrows(): \n","  if row.SUBJECT_ID in patient_set: \n","    age_vec[patient_index_of[row.SUBJECT_ID]][0] = (age_at_admission[row.SUBJECT_ID].total_seconds() / 3600.0)\n","    if row.GENDER == 'M': \n","      gender_one_hot[patient_index_of[row.SUBJECT_ID]][0] = 1\n","    else: \n","      gender_one_hot[patient_index_of[row.SUBJECT_ID]][1] = 1\n","\n","static_vec = np.concatenate((gender_one_hot, age_vec), axis = 1)\n","# [num_patients, 3]\n","\n","chart_vec = chart_X / (chart_Xcnt + (chart_Xcnt == 0))\n","lab_vec = lab_X / (lab_Xcnt + (lab_Xcnt == 0))\n","surgery_vec = surgery_X / (surgery_Xcnt + (surgery_Xcnt == 0))\n","\n","for i in range(len(patient_set)): \n","  chart_vec[i] = forward_backward_impute(chart_vec[i], global_chart_mean)\n","  lab_vec[i] = forward_backward_impute(lab_vec[i], global_lab_mean)\n","  surgery_vec[i] = forward_backward_impute(surgery_vec[i],  global_surgery_mean)\n","\n","time_vec = np.concatenate((lab_vec, chart_vec, surgery_vec), axis=2)\n","# time_vec [num_patients, max_hours, num_lab_features + num_chart_features + num_vital_features]\n","\n","# concatenate this with static_vec [num_patients, 3]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D8JQLQnOb-t8","colab_type":"text"},"source":["**cohort** is a list of indices that you're training / testing on. For instance, if I want the patients with ID's 5, 10, 6, then cohort [patient_index_of[5], patient_index_of[10], patient_index_of[6]].\n","\n","If you want to test a certain age cohort, then **cohort** should be the a list of indices of patients in that age cohort. "]},{"cell_type":"markdown","metadata":{"id":"alE7SPf4mYwZ","colab_type":"text"},"source":["Ok here I'm going to set up a DataLoader for the tasks."]},{"cell_type":"code","metadata":{"id":"81bVlxXhXUzK","colab_type":"code","colab":{}},"source":["from torch.utils.data import DataLoader, Dataset\n","\n","BATCH_SIZE = 16\n","\n","class MyDataset(Dataset): \n","  def __init__(self, feats, values, statics): \n","    self.feats = feats # features you're ingesting\n","    self.values = values # value aggregate in the prediction window\n","    self.statics = statics # demographic features corresponding to this guy\n","  def __len__(self): \n","    return self.feats.size(0)\n","  def __getitem__(self, index): \n","    return self.feats[index], self.values[index], self.statics[index]\n","\n","def get_dataloader(indices, model_type, test = False): \n","  my_feats = []\n","  my_values = []\n","  my_statics = []\n","  for i in indices:   \n","    for t_start in range(MAX_HOURS - WINDOW_SIZE - GAP_TIME - PRED_SIZE): \n","      if window_cnt[i][t_start] > 0: \n","        my_feats.append(time_vec[i][t_start:t_start+WINDOW_SIZE])\n","        my_values.append(feat_agg[i][t_start])\n","        my_statics.append(static_vec[i])\n","  if model_type == 'LSTM': \n","    if test: \n","      return DataLoader(MyDataset(torch.tensor(my_feats).float(), torch.tensor(my_values).float(), torch.tensor(my_statics).float()), \n","                      batch_size=1, \n","                      shuffle=True, \n","                      drop_last=True)\n","    else: \n","      return DataLoader(MyDataset(torch.tensor(my_feats).float(), torch.tensor(my_values).float(), torch.tensor(my_statics).float()), \n","                      batch_size=BATCH_SIZE, \n","                      shuffle=True, \n","                      drop_last=True)\n","  else: \n","    return my_feats, my_values, my_statics\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"awrHKenufEm6","colab_type":"text"},"source":["Here, we're going to set up a cohort to test. Call this prior to train_rf or train_lstm."]},{"cell_type":"code","metadata":{"id":"-Qnhhqqde_dv","colab_type":"code","colab":{}},"source":["def set_up_cohort(cohort): \n","  global time_vec\n","  global static_vec\n","  msk = np.array([False for i in range(len(time_vec))])\n","  for p in cohort: \n","    msk[p] = True \n","  scaler1 = StandardScaler()\n","  scaler2 = StandardScaler() \n","  time_vec = np.array(time_vec)\n","  static_vec = np.array(static_vec)\n","  shp = time_vec[msk, ...].shape \n","  time_vec[msk, ...] = scaler1.fit_transform(time_vec[msk, ...].reshape(-1, shp[-1])).reshape(shp)\n","  static_vec[msk, ...] = scaler2.fit_transform(static_vec[msk, ...])\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aimbxXPuhqHf","colab_type":"text"},"source":["Now we have our RF helper functions."]},{"cell_type":"code","metadata":{"id":"szGv-3ppjq9L","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import roc_auc_score\n","from sklearn.metrics import roc_curve\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","def train_rf(task, cohort, n_estimators=200, bootstrap=True, max_features='sqrt'): \n","  train_indices, test_indices = train_test_split(np.array(cohort), test_size=0.2)\n","\n","  train_data = get_dataloader(train_indices, 'RF')\n","  test_data = get_dataloader(test_indices, 'RF')\n","  \n","  x_train = np.array(train_data[0])\n","  x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n","  x_train = np.concatenate((x_train, np.array(train_data[2])), axis=1)\n","  ### Obviously change this.\n","  print(len(np.array(train_data[1])))\n","  print(\"max\",np.array(train_data[1]).max())\n","  print(\"min\",np.array(train_data[1]).min())\n","  print(\"mean\",np.array(train_data[1]).mean())\n","  print(np.array(train_data[1]))\n","  y_train = np.int_(np.array(train_data[1]) < 4)\n","  ###\n","  x_test = np.array(test_data[0])\n","  x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2]))\n","  x_test = np.concatenate((x_test, np.array(test_data[2])), axis=1)\n","\n","  ### And this.\n","  y_test = np.int_(np.array(test_data[1]) < 4)\n","  ###\n","\n","  model = RandomForestClassifier(n_estimators=n_estimators, \n","                             bootstrap = bootstrap,\n","                             max_features = max_features)\n","  \n","  model.fit(x_train, y_train)\n","\n","  return model, x_test, y_test\n","\n","def evaluate_rf(model, x_test, y_test): \n","\n","  rf_predictions = model.predict(x_test)\n","  print(model.predict_proba(x_test))\n","  rf_probs = model.predict_proba(x_test)[:, 1]\n","  print(rf_probs)\n","  auc = roc_auc_score(y_test, rf_probs)\n","  acc = np.sum(rf_predictions == y_test) / len(y_test)\n","\n","  return auc, acc, rf_predictions, rf_probs \n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y0LyoBbValp-","colab_type":"code","colab":{}},"source":["from sklearn.metrics import roc_curve\n","def plot_roc(title, labels, probs): \n","  fpr, tpr, thresholds = roc_curve(labels, probs) \n","  plt.figure()\n","  plt.plot(fpr, tpr, label=title)\n","  plt.plot([0, 1], [0, 1],'r--')\n","  plt.xlim([0.0, 1.0])\n","  plt.ylim([0.0, 1.05])\n","  plt.xlabel('1 - Specificity')\n","  plt.ylabel('Sensitivity')\n","  plt.title('ROC')\n","  plt.legend(loc=\"lower right\")\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10cnz5AjMg-f","colab_type":"text"},"source":["Note we need to further preprocess this data (zero mean, unit variance, PCA, etc..)\n"]},{"cell_type":"markdown","metadata":{"id":"MHdEiweyE1aA","colab_type":"text"},"source":["RF Helper Funcs"]},{"cell_type":"code","metadata":{"id":"dO2_0Lgqter7","colab_type":"code","colab":{}},"source":["model_filename = 'AUC_rf_cohort4_WBC.sav'\n","effect_filename='RF_model_cohort4_WBC.pt'\n","LSTM_filename='LSTM_model_cohort4_WBC.pt'\n","def get_mask(remove_these): \n","  msk = [True for i in range(len(patient_set))]\n","  for p in remove_these: \n","    msk[patient_index_of[p]] = False\n","  return msk \n","\n","def run_task_rf(task): \n","  \n","  cohort = [i for i in range(len(patient_set))]\n","  mask = get_mask(subjects_to_remove)\n","  cohort = np.array(cohort)[mask, ...]\n","\n","  COHORTS = ['Total', '0 - 2 Month', '2 Month - 2 Years', '2 Years - 5 Years', '5 Years - 12 Years']\n","  THRESHOLDS = [-1, 60 * 24, 2 * 365 * 24, 5 * 365 * 24, 12 *  365 * 24]  \n","\n","  min_age=THRESHOLDS[2]\n","  max_age=THRESHOLDS[3]\n","\n","  my_msk = [True for i in range(len(cohort))]\n","  for i in range(len(cohort)): \n","    age_here = static_vec[cohort[i]][-1]\n","    if age_here < min_age: \n","      my_msk[i] = False\n","    elif age_here > max_age: \n","      my_msk[i] = False \n","  \n","  cohort = cohort[my_msk, ...]\n","\n","  set_up_cohort(cohort)\n","  model, x_test, y_test = train_rf(task, cohort)\n","\n","  auc, acc, _, _ = evaluate_rf(model, x_test, y_test)\n","\n","  return auc, acc, model\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aJvE4q8_5iM-","colab_type":"code","colab":{}},"source":["auc, acc, model_to_save = run_task_rf('Lab Test Prediction')\n","print(\"AUC of \", auc)\n","print(\"ACC of \", acc)\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbmlIeHmSIv2","colab_type":"code","colab":{}},"source":["print(age_at_admission[12879])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_1_j9KPiEsoc","colab_type":"code","colab":{}},"source":["import pickle\n","#filename = 'WBC_all_AUC_80.sav'\n","from google.colab import drive\n","#drive.mount('gdrive')\n","from google.colab import files\n","#files.download(pickle.dump(model))\n","#from google.colab import files\n","pickle.dump(model_to_save, open(model_filename, 'wb'))\n","files.download(model_filename)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0CjoKqehwGRM","colab_type":"text"},"source":["# Change this function. Here I'm getting the input X and label Y from the dataloader features.\n","\n","Currently, I'm defining the labels as WBC < 20."]},{"cell_type":"code","metadata":{"id":"JhXXTpCjxVLI","colab_type":"code","colab":{}},"source":["TRAIN_BATCHES_PER_EPOCH = 1000\n","TEST_SAMPLES = 2000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y_OThJ2CtTz-","colab_type":"code","colab":{}},"source":["def get_XY(feats, values, statics):\n","  # feats is B x WINDOW x dim_input\n","  # values is B\n","  # statics is B x 3\n","  X = torch.cat((torch.tensor(feats), torch.tensor(statics).unsqueeze(1).expand((len(feats), len(feats[0]), len(statics[-1])))), dim=-1)\n","  Y = torch.tensor(torch.tensor(values) < 4).float()\n","\n","  return X, Y\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnnolY1UxTOA","colab_type":"code","colab":{}},"source":["class LSTM_Classifier(nn.Module):\n","  def __init__(self, input_size, hidden_size, num_layers=1, dropout=0., bidirectional=False):\n","    super(LSTM_Classifier, self).__init__()\n","\n","    self.input_size = input_size\n","    self.hidden_size = hidden_size\n","    self.num_layers = num_layers \n","    self.bidirectional = bidirectional\n","    self.dropout = dropout\n","\n","    self.rnn = nn.LSTM(input_size, hidden_size, num_layers=num_layers, batch_first=True,\n","                      dropout=dropout, bidirectional=bidirectional)\n","    self.out = nn.Linear(hidden_size + hidden_size * int(bidirectional), 1)\n","\n","  def forward(self, input):\n","    # Input is (B, seq_len, input_size)\n","    rnn_out, _ = self.rnn(input)\n","    # rnn_out is (B, seq_len, directions * hidden_size)\n","    # output is (B, seq_len, 1)\n","    return self.out(rnn_out)\n","\n","def rnn_train_one_sample(model, criterion, rnn_optimizer, sent_tensor, tag_tensor, alpha = 0.5, clip=None):\n","\n","    # sent_tensor is (B, Num Hours, Num feats)\n","    # tag_tensor is (B)\n","\n","    model.zero_grad() \n","\n","    outputs = model(sent_tensor).squeeze(2)\n","\n","    # loss = criterion(outputs, tag_tensor) * alpha + criterion(outputs[-1], tag_tensor[-1]) * (1.0-alpha)\n","    loss = criterion(outputs[:, -1], tag_tensor) \n","\n","    loss.backward()\n","\n","    if clip != None: \n","      torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=clip)\n","\n","    rnn_optimizer.step()\n","\n","    return outputs, loss.item()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jhgk4icHmNFz","colab_type":"code","colab":{}},"source":["import time\n","import math\n","import sklearn\n","from sklearn.metrics import precision_recall_fscore_support\n","\n","def timeSince(since):\n","    now = time.time()\n","    s = now - since\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def evaluate_result(true_tag_list, predicted_tag_list, probs):\n","  return np.mean(true_tag_list.numpy() == predicted_tag_list), roc_auc_score(true_tag_list, probs)\n","\n","# Make prediction for one sentence.\n","def rnn_predict_one_sent(model, sent_tensor):\n","  \n","    outputs = model(sent_tensor).squeeze(2).squeeze(0)\n","    prob = torch.sigmoid(outputs[-1])\n","\n","    predicted_tag_id = 0\n","    if prob > 0.5: \n","      predicted_tag_id = 1\n","    \n","    return predicted_tag_id, prob.item()\n","\n","\n","def evaluate_rnn(model, test_dataloader): \n","  \n","  model.eval()\n","  predicted_tags = []\n","  probs = []\n","  labels = []\n","\n","  iter_count = 0\n","  for feats, values, statics in test_dataloader:\n","    iter_count += 1\n","    if iter_count > TEST_SAMPLES: \n","      break \n","\n","    sent_tensor, tag_tensor = get_XY(feats, values, statics) \n","    sent_tensor = sent_tensor.to(device)\n","    predicted_tag_id, prob = rnn_predict_one_sent(model, sent_tensor)\n","    predicted_tags.append(predicted_tag_id)\n","    probs.append(prob)\n","    labels.append(tag_tensor[0].item())\n","\n","\n","  acc, auc = evaluate_result(torch.tensor(labels), predicted_tags, probs)\n","\n","  return auc, acc, predicted_tags, probs \n","\n","def train_model(model, criterion, optimizer, train_dataloader, test_dataloader, n_epochs=5, print_every=100, plot_every=50, learning_rate=1e-3, alpha = 0.5, clip=None): \n","\n","  iter_count = 0\n","\n","  current_loss = 0\n","  current_norm = 0\n","  all_losses = []\n","  all_norms = []\n","\n","  start = time.time()\n","\n","  model.train()\n","  for epoch_i in range(n_epochs):\n","    num_batches = 0\n","    for feats, values, statics in train_dataloader: \n","      num_batches += 1\n","      if num_batches > TRAIN_BATCHES_PER_EPOCH: \n","        break \n","\n","      sent_tensor, tag_tensor = get_XY(feats, values, statics)\n","    \n","      sent_tensor = sent_tensor.to(device)\n","      tag_tensor = tag_tensor.to(device)\n","  \n","      output, loss = rnn_train_one_sample(model, criterion, optimizer, sent_tensor, tag_tensor, alpha=alpha, clip=clip)\n","      current_loss += loss\n","\n","      if iter_count % print_every == 0:\n","          print('%d %s %.4f' % (iter_count, timeSince(start), current_loss / print_every))\n","          current_loss = 0\n","\n","      iter_count += 1\n","\n","    auc, acc, _, _ = evaluate_rnn(model, test_dataloader)\n","    print(\"Epoch \", epoch_i, \" ACC of \", acc, \" AUC of \", auc)\n","  return all_losses, all_norms\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qn9G3K8B0E7g","colab_type":"code","colab":{}},"source":["def train_rnn(task, cohort, n_epochs=10, \n","              rnn_clip = 1.0, \n","              rnn_hidden_size = 64, \n","              rnn_num_layers = 2, \n","              learning_rate = 1e-4, \n","              rnn_dropout = 0.5, \n","              rnn_alpha = 0.5, \n","              weight_decay = 1e-4,\n","              rnn_bidirectional = False): \n","\n","  num_feats = time_vec.shape[-1] + 3\n","\n","  train_indices, test_indices = train_test_split(np.array(cohort), test_size=0.2)\n","\n","  train_dataloader = get_dataloader(train_indices, 'LSTM')\n","  test_dataloader = get_dataloader(test_indices, 'LSTM', test=True)\n","\n","  rnn_model = LSTM_Classifier(input_size=num_feats, hidden_size=rnn_hidden_size, num_layers=rnn_num_layers, dropout=rnn_dropout, bidirectional=rnn_bidirectional)\n","  criterion = nn.BCEWithLogitsLoss()\n","  rnn_optimizer = torch.optim.Adam(rnn_model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","\n","  losses, norms = train_model(rnn_model, criterion, rnn_optimizer, train_dataloader, test_dataloader, n_epochs=n_epochs, alpha=rnn_alpha, clip=rnn_clip)\n","\n","  return rnn_model, test_dataloader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_sjaOKT1q85","colab_type":"code","colab":{}},"source":["# Evaluation\n","\n","def get_mask(remove_these): \n","  msk = [True for i in range(len(patient_set))]\n","  for p in remove_these: \n","    msk[patient_index_of[p]] = False\n","  return msk \n","\n","def run_task_rnn(task): \n","\n","  cohort = [i for i in range(len(patient_set))]\n","  mask = get_mask(subjects_to_remove)\n","  cohort = np.array(cohort)[mask, ...]\n","  set_up_cohort(cohort)\n","  model, test_dataloader = train_rnn(task, cohort)\n","\n","  auc, acc, _, _ = evaluate_rnn(model, test_dataloader)\n","\n","  return model, auc, acc, test_dataloader\n","\n"," "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SId853IVZLSx","colab_type":"text"},"source":["Set up data and evaluate."]},{"cell_type":"code","metadata":{"id":"L9nQknnDRm9E","colab_type":"code","colab":{}},"source":["model, auc, acc, test_dataloader = run_task_rnn('LAB TEST PREDICTION')\n","print(\"AUC of \", auc)\n","print(\"ACC of \", acc)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6PE7jBpM19ZJ","colab_type":"code","colab":{}},"source":["xt = torch.zeros((TEST_SAMPLES, WINDOW_SIZE, time_vec.shape[-1] + 3))\n","\n","torch.save(model,effect_filename)\n","files.download(effect_filename)\n","\n","torch.save(model,LSTM_filename)\n","files.download(LSTM_filename)\n","\n","cnt = 0\n","for feats, values, statics in test_dataloader:\n","    cnt += 1\n","    if cnt > TEST_SAMPLES: \n","      break \n","    sent_tensor, tag_tensor = get_XY(feats, values, statics) \n","    xt[cnt-1] = sent_tensor.squeeze(0)\n","torch.save(xt,'xt.pt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkTtEFxvZDof","colab_type":"code","colab":{}},"source":["torch.save(xt,'xt.pt')\n","\n","#torch.load('xt.pt')\n","\n","effects = perturb_features(model, xt)\n","print(effects)\n","for t in effects:\n","  print(t[1])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UsjOZrkF1_oD","colab_type":"code","colab":{}},"source":["\n","torch.save(effects,effect_filename)\n","files.download(effect_filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ie0QAYkwhDDs","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2dP27N_K7ENa","colab_type":"code","colab":{}},"source":["COHORTS = ['Total', '0 - 2 Month', '2 Month - 2 Years', '2 Years - 5 Years', '5 Years - 12 Years']\n","THRESHOLDS = [-1, 60 * 24, 2 * 365 * 24, 5 * 365 * 24, 12 *  365 * 24]"],"execution_count":0,"outputs":[]}]}